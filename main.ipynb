{"cells":[{"cell_type":"code","source":["import os\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount(\"/content/drive\")\n","\n","%cd \"/content/drive/MyDrive/CS5780/Movie-Review-Preference-Analysis\"\n","\n","# Verify the current working directory\n","print(\"Current working directory:\", os.getcwd())\n","\n","# List the contents of the folder\n","folder_contents = os.listdir()\n","print(folder_contents)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sN61pY7z7TcW","executionInfo":{"status":"ok","timestamp":1704118823109,"user_tz":300,"elapsed":20540,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"3c91d69c-dccf-41b2-af8e-607452ffe6d0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/CS5780/Movie-Review-Preference-Analysis\n","Current working directory: /content/drive/MyDrive/CS5780/Movie-Review-Preference-Analysis\n","['README.md', '.gitignore', 'try.ipynb', 'LICENSE', 'data', 'architecture_result.csv', 'submission.csv', 'main.ipynb']\n"]}]},{"cell_type":"markdown","metadata":{"id":"DMo8ScON7HGw"},"source":["# 1. Import"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"96_Rk9xF7HGz","executionInfo":{"status":"ok","timestamp":1704118829366,"user_tz":300,"elapsed":6260,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}}},"outputs":[],"source":["import random\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","from typing import Optional\n","import itertools\n","\n","# Sklearn\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import StandardScaler\n","\n","# Torch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.nn.init as init\n","from torch.utils.data import DataLoader, TensorDataset"]},{"cell_type":"markdown","metadata":{"id":"ydHGXDTe7HG1"},"source":["# 2. Data Loading"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"TpJDfCkc7HG1","executionInfo":{"status":"ok","timestamp":1704118832159,"user_tz":300,"elapsed":2805,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}}},"outputs":[],"source":["import numpy as np\n","\n","def load_npz(file_path):\n","    with np.load(file_path) as data:\n","        return {key: data[key] for key in data}\n","\n","train_data = load_npz(r'./data/train.npz')\n","test_data = load_npz(r'./data/test.npz')\n","train_emb1, train_emb2, train_labels = train_data['emb1'], train_data['emb2'], train_data['preference']\n","test_emb1, test_emb2 = test_data['emb1'], test_data['emb2']"]},{"cell_type":"markdown","metadata":{"id":"55mDrZIL7HG2"},"source":["# 3. Exploration"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"upz4wbsx7HG2","executionInfo":{"status":"ok","timestamp":1704118832160,"user_tz":300,"elapsed":9,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"97456dac-7dca-48e1-bbf7-2ed164f9aabb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'uid': array([    0,     1,     2, ..., 18747, 18748, 18749]),\n"," 'emb1': array([[-0.05075016, -0.03491386, -0.05787281, ...,  0.00020284,\n","          0.02388327, -0.02491781],\n","        [-0.12402835, -0.07631648, -0.05782915, ...,  0.02713838,\n","          0.01394665,  0.0186507 ],\n","        [-0.06794146, -0.0385992 ,  0.04476113, ...,  0.07999779,\n","          0.04943484,  0.00783883],\n","        ...,\n","        [ 0.02096516, -0.00752076, -0.06958353, ...,  0.01346127,\n","          0.01917063, -0.06059628],\n","        [-0.00901941,  0.01330765, -0.02343761, ..., -0.02690429,\n","          0.0084649 ,  0.01999134],\n","        [-0.05510234,  0.00251053, -0.01775946, ...,  0.00322949,\n","         -0.02700103,  0.01986161]], dtype=float32),\n"," 'emb2': array([[-0.03255587,  0.01327268, -0.00508326, ..., -0.01196616,\n","         -0.03564733, -0.03713938],\n","        [-0.00014027,  0.03904634,  0.0592997 , ...,  0.00117963,\n","          0.04012304,  0.07394706],\n","        [-0.068197  , -0.0943828 ,  0.04236921, ...,  0.0225933 ,\n","          0.00185285, -0.03076085],\n","        ...,\n","        [ 0.00845952,  0.00125914, -0.03183057, ..., -0.04645595,\n","         -0.00618974,  0.00794393],\n","        [-0.05969298,  0.00475971,  0.00906092, ..., -0.0083008 ,\n","         -0.05037842, -0.02749569],\n","        [-0.04472147, -0.01137812, -0.05518954, ..., -0.05703627,\n","          0.03633969,  0.00122035]], dtype=float32),\n"," 'preference': array([1, 1, 1, ..., 1, 0, 0], dtype=int8)}"]},"metadata":{},"execution_count":4}],"source":["train_data"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OzFiCpuJ7HG3","executionInfo":{"status":"ok","timestamp":1704118832160,"user_tz":300,"elapsed":8,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"fc576721-44eb-4a19-d85b-212f68146752"},"outputs":[{"output_type":"stream","name":"stdout","text":["Length of 'uid': 18750\n","Length of 'emb1': 18750\n","Length of 'emb2': 18750\n","Length of 'preference': 18750\n"]}],"source":["for key, value in train_data.items():\n","    print(f\"Length of '{key}': {len(value) if isinstance(value, np.ndarray) else 'Not an array'}\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cUzDZgn-7HG4","executionInfo":{"status":"ok","timestamp":1704118832160,"user_tz":300,"elapsed":6,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"a677ae74-8679-4194-96e9-aa28d2196513"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['uid', 'emb1', 'emb2', 'preference'])"]},"metadata":{},"execution_count":6}],"source":["train_data.keys()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wu2YC6pQ7HG5","executionInfo":{"status":"ok","timestamp":1704118832360,"user_tz":300,"elapsed":204,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"44fdeb58-f6a7-43c5-92c5-431e40f0037b"},"outputs":[{"output_type":"stream","name":"stdout","text":["(384,)\n","(384,)\n","1\n"]}],"source":["# x1\n","print(train_data['emb1'][0].shape) # (384,)\n","# x2\n","print(train_data['emb2'][0].shape) # (384,)\n","# y\n","print(train_data['preference'][0]) # 1\n","# train_data['emb1'][0]"]},{"cell_type":"markdown","metadata":{"id":"K13TWsem7HG5"},"source":["# 4. Preprocessing"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"cZtJpS9_7HG5","executionInfo":{"status":"ok","timestamp":1704118832360,"user_tz":300,"elapsed":7,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}}},"outputs":[],"source":["## Parameters\n","\n","# Preprocessing Parameters\n","validation_size = 0.2\n","RAND_STATE = 5780\n","shuffle_split = True\n","standardized = False"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"hNpepn9i7HG6","executionInfo":{"status":"ok","timestamp":1704118832361,"user_tz":300,"elapsed":7,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}}},"outputs":[],"source":["def train_validation_split(Xs, Ys, validation_size: float=0.2):\n","    Xs_tr, Xs_va, Ys_tr, Ys_va = train_test_split(Xs, Ys, test_size=validation_size, random_state=RAND_STATE, shuffle=shuffle_split, stratify=Ys)\n","    return torch.Tensor(Xs_tr), torch.Tensor(Xs_va), torch.Tensor(Ys_tr).long(), torch.Tensor(Ys_va).long()"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"YdMOBMhA7HG6","executionInfo":{"status":"ok","timestamp":1704118832361,"user_tz":300,"elapsed":7,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}}},"outputs":[],"source":["def standardization(Xs):\n","    scaler = StandardScaler()\n","    Xs_scaled = scaler.fit_transform(Xs)\n","    return torch.Tensor(Xs_scaled)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H4o3oeyq7HG6","executionInfo":{"status":"ok","timestamp":1704118832361,"user_tz":300,"elapsed":7,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"39a974b4-464c-40ad-9ba6-a55b8577eb91"},"outputs":[{"output_type":"stream","name":"stdout","text":["(18750, 384)\n","(18750, 384)\n","Xs_tr.shape: torch.Size([15000, 768])\n","Ys_tr.shape: torch.Size([15000])\n","Xs_va.shape: torch.Size([3750, 768])\n","Ys_va.shape: torch.Size([3750])\n"]}],"source":["print(train_data['emb1'].shape) # (n x d): (18750, 384)\n","print(train_data['emb2'].shape) # (n x d): (18750, 384)\n","\n","# Concatenate the input in to a single long vector\n","Xs = np.concatenate((train_data['emb1'], train_data['emb2']), axis=1)\n","Ys = train_data['preference']\n","\n","# Train Validation Split\n","Xs_tr, Xs_va, Ys_tr, Ys_va = train_validation_split(Xs, Ys, validation_size)\n","\n","if standardized:\n","    Xs_tr = standardization(Xs_tr)\n","    Xs_va = standardization(Xs_va)\n","\n","# Convert to Torch\n","print(f'Xs_tr.shape: {Xs_tr.shape}')\n","print(f'Ys_tr.shape: {Ys_tr.shape}')\n","print(f'Xs_va.shape: {Xs_va.shape}')\n","print(f'Ys_va.shape: {Ys_va.shape}')"]},{"cell_type":"markdown","metadata":{"id":"byz65kva7HG6"},"source":["# 5. Model"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"9wpZeMvc7HG6","executionInfo":{"status":"ok","timestamp":1704118832361,"user_tz":300,"elapsed":5,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}}},"outputs":[],"source":["# Parameters\n","embedding_dim = 768\n","hidden_dim = 128\n","output_dim = 2\n","num_layers = 1\n","activation = \"relu\"\n","\n","# Improvement\n","dropout_rate = 0.5\n","include_batch_norm = True\n","initialize_weights = False"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"PdfQEGym7HG7","executionInfo":{"status":"ok","timestamp":1704118832361,"user_tz":300,"elapsed":5,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}}},"outputs":[],"source":["# FFNN Model\n","class FFNN(nn.Module):\n","    def __init__(\n","        self,\n","        embedding_dim: int,\n","        hidden_dim: int,\n","        output_dim: int,\n","        activation: str = \"relu\",\n","        num_layers: int = 1,\n","        include_batch_norm: bool = False,\n","        initialize_weights: bool = False,\n","        dropout_rate: Optional[float] = None\n","    ) -> None:\n","\n","        super().__init__()\n","        assert num_layers > 0\n","\n","        # FFNN architecture attributes\n","        self.embedding_dim = embedding_dim\n","        self.hidden_dim = hidden_dim\n","        self.output_dim = output_dim\n","        self.activation = activation\n","        self.num_layers = num_layers\n","\n","        # Layer attributes\n","        self.input_layer = nn.Linear(self.embedding_dim, self.hidden_dim)\n","        self.hidden_layers = nn.ModuleList()\n","        for _ in range(self.num_layers - 1):\n","            self.hidden_layers.append(nn.Linear(self.hidden_dim, self.hidden_dim))\n","        self.output_layer = nn.Linear(self.hidden_dim, self.output_dim)\n","\n","        # Weight initialization attributes\n","        self.initialize_weights = initialize_weights\n","        if initialize_weights:\n","            init.xavier_normal_(self.input_layer.weight)\n","            for hidden_layer in self.hidden_layers:\n","                init.xavier_normal_(hidden_layer.weight)\n","            init.xavier_normal_(self.output_layer.weight)\n","\n","        # FFNN performance improvement attributes\n","        self.dropout_rate = dropout_rate\n","        if dropout_rate is not None:\n","            self.dropout = nn.Dropout(p=self.dropout_rate)\n","        else:\n","            self.dropout = None\n","        self.include_batch_norm = include_batch_norm\n","        if include_batch_norm:\n","            self.batch_norm = nn.BatchNorm1d(self.hidden_dim)\n","\n","    def forward(self, embeddings: torch.Tensor) -> torch.Tensor:\n","        x = self.input_layer(embeddings)\n","        for hidden_layer in self.hidden_layers:\n","            # Forward layer\n","            x = hidden_layer(x)\n","\n","            # Batch normalization layer\n","            if self.include_batch_norm:\n","                x = self.batch_norm(x)\n","\n","            # Non-linear layer\n","            if self.activation == \"relu\":\n","                x = F.relu(x)\n","            elif self.activation == \"tanh\":\n","                x = F.tanh(x)\n","            elif self.activation == \"sigmoid\":\n","                x = F.sigmoid(x)\n","\n","            # Drop out regularization layer\n","            if self.dropout_rate is not None:\n","                x = self.dropout(x)\n","        output = self.output_layer(x)\n","        return output"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jMEzeTU37HG7","executionInfo":{"status":"ok","timestamp":1704118832361,"user_tz":300,"elapsed":5,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"a867916c-9f33-4d69-8edc-2dbdda5ac624"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["FFNN(\n","  (input_layer): Linear(in_features=768, out_features=128, bias=True)\n","  (hidden_layers): ModuleList()\n","  (output_layer): Linear(in_features=128, out_features=2, bias=True)\n","  (batch_norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",")"]},"metadata":{},"execution_count":14}],"source":["# Test\n","ffnn = FFNN(\n","    embedding_dim=embedding_dim,\n","    hidden_dim=hidden_dim,\n","    output_dim=output_dim,\n","    activation=activation,\n","    num_layers=num_layers,\n","    include_batch_norm=include_batch_norm,\n","    initialize_weights=initialize_weights,\n",")\n","ffnn"]},{"cell_type":"markdown","metadata":{"id":"3z4NLmRg7HG7"},"source":["# 6. Model Training"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"TsybdVyT7HG7","executionInfo":{"status":"ok","timestamp":1704118838103,"user_tz":300,"elapsed":2126,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}}},"outputs":[],"source":["# Parameters\n","epochs = 10\n","batch_size = 100\n","alpha = 0.1\n","beta = 0.9\n","rho1 = 0.99\n","rho2 = 0.999\n","# grad_clip_max_norm = 1\n","\n","# Optimizers\n","sgd_optimizer = torch.optim.SGD(ffnn.parameters(), lr=alpha)\n","adam_optimizer = torch.optim.Adam(ffnn.parameters(), lr=alpha)\n","adamw_optimizer = torch.optim.AdamW(ffnn.parameters(), lr=alpha)\n","rmsprop_optimizer = torch.optim.RMSprop(ffnn.parameters(), lr=alpha)\n","\n","# Loss functions\n","binary_cross_entropy_loss_fn = torch.nn.BCELoss()\n","cross_entropy_loss_fn = torch.nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"NhKgxsRn7HG7","executionInfo":{"status":"ok","timestamp":1704118838103,"user_tz":300,"elapsed":2,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}}},"outputs":[],"source":["# evaluate a trained model on MNIST data\n","#\n","# dataloader    dataloader of examples to evaluate on\n","# model         trained PyTorch model\n","# loss_fn       loss function (e.g. torch.nn.CrossEntropyLoss)\n","#\n","# returns       tuple of (loss, accuracy), both python floats\n","@torch.no_grad()\n","def evaluate_model(Xs_va, Ys_va, model, loss_fn):\n","\tmodel.eval()\n","\ttotal_loss = 0.0\n","\ttotal_correct = 0\n","\ttotal_samples = 0\n","\n","\t# Create DataLoader for batching\n","\tvalidation_dataset = TensorDataset(Xs_va, Ys_va)\n","\tvalidation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n","\n","\tfor X, Y in validation_loader:\n","\t\tY_pred_prob = model(X)\n","\t\tloss = loss_fn(Y_pred_prob, Y)\n","\t\ttotal_loss += loss.item()\n","\n","\t\tY_pred = torch.argmax(Y_pred_prob, dim=1)\n","\t\ttotal_correct += torch.sum(Y_pred == Y).item()\n","\t\ttotal_samples += Y.size(0)\n","\n","\taverage_loss = total_loss / len(validation_loader)\n","\taccuracy = total_correct / total_samples\n","\n","\treturn average_loss, accuracy"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"ej0GG7EH7HG7","executionInfo":{"status":"ok","timestamp":1704118840975,"user_tz":300,"elapsed":3,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}}},"outputs":[],"source":["def train(Xs_tr, Ys_tr, Xs_va, Ys_va, model, loss_fn, optimizer, epochs, batch_size, grad_clip_max_norm: Optional[float] = None):\n","    validation_losses = []\n","    validation_accuracies = []\n","\n","    # Create DataLoader for batching\n","    train_dataset = TensorDataset(Xs_tr, Ys_tr)\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","    for epoch in range(epochs):\n","        # Set to training mode\n","        model.train()\n","\n","        total_loss = 0.0\n","\n","        for i, (X, Y) in enumerate(train_loader):\n","            # Zero gradients for every batch\n","            optimizer.zero_grad()\n","\n","            # Make predictions for this batch\n","            Y_pred_prob = model(X)\n","\n","            # Compute the loss and its gradients\n","            loss = loss_fn(Y_pred_prob, Y)\n","            loss.backward()\n","\n","            if grad_clip_max_norm is not None:\n","                nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip_max_norm)\n","\n","            # Adjust learning weights\n","            optimizer.step()\n","\n","            # Gather data and report\n","            total_loss += loss.item()\n","\n","        # # Calculate average training loss\n","        # avg_train_loss = total_loss / len(train_loader)\n","\n","        # Evaluate the model\n","        validation_loss, validation_accuracy = evaluate_model(Xs_va, Ys_va, model, loss_fn)\n","        validation_losses.append(validation_loss)\n","        validation_accuracies.append(validation_accuracy)\n","        print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {loss.item()}, Validation Loss: {validation_loss:.3f}, Validation Accuracy: {validation_accuracy:.3f}\")\n","\n","    best_validation_loss = min(validation_losses)\n","    best_validation_accuracy = max(validation_accuracies)\n","    print(f\"Minimum Loss: {best_validation_loss:.3f}, Max Accuracy: {best_validation_accuracy:.3f}\")\n","    return best_validation_loss, best_validation_accuracy"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ERBV3opF7HG8","executionInfo":{"status":"ok","timestamp":1704118849035,"user_tz":300,"elapsed":5365,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"46a2a163-12a7-4840-f587-b0b5cc4db732"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Training Loss: 0.3509211838245392, Validation Loss: 0.288, Validation Accuracy: 0.883\n","Epoch 2/10, Training Loss: 0.2655160427093506, Validation Loss: 0.277, Validation Accuracy: 0.886\n","Epoch 3/10, Training Loss: 0.3295680284500122, Validation Loss: 0.323, Validation Accuracy: 0.870\n","Epoch 4/10, Training Loss: 0.3030592203140259, Validation Loss: 0.343, Validation Accuracy: 0.873\n","Epoch 5/10, Training Loss: 0.3285124897956848, Validation Loss: 0.664, Validation Accuracy: 0.771\n","Epoch 6/10, Training Loss: 0.7560265064239502, Validation Loss: 0.696, Validation Accuracy: 0.831\n","Epoch 7/10, Training Loss: 0.8313727378845215, Validation Loss: 1.205, Validation Accuracy: 0.873\n","Epoch 8/10, Training Loss: 1.1097652912139893, Validation Loss: 1.025, Validation Accuracy: 0.865\n","Epoch 9/10, Training Loss: 0.5087457299232483, Validation Loss: 0.894, Validation Accuracy: 0.848\n","Epoch 10/10, Training Loss: 0.8999691605567932, Validation Loss: 1.169, Validation Accuracy: 0.858\n","Minimum Loss: 0.277, Max Accuracy: 0.886\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.27683932726320465, 0.8864)"]},"metadata":{},"execution_count":18}],"source":["# FFNN\n","train(Xs_tr, Ys_tr, Xs_va, Ys_va, ffnn, cross_entropy_loss_fn, adam_optimizer, epochs, batch_size, grad_clip_max_norm=None)"]},{"cell_type":"markdown","metadata":{"id":"TBD29j717HG8"},"source":["# 7. Hyperparameter Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4UyzPJJi7HG8"},"outputs":[],"source":["# Architecture Parameters\n","embedding_dim = 768\n","hidden_dim = 128\n","output_dim = 2\n","num_layers = 1\n","activation = \"relu\"\n","\n","# Architecture Improvement Parameters\n","dropout_rate = 0.5\n","include_batch_norm = True\n","initialize_weights = False\n","\n","# Training Parameters\n","epochs = 10\n","batch_size = 100\n","alpha = 0.1\n","beta = 0.9\n","rho1 = 0.99\n","rho2 = 0.999\n","grad_clip_max_norm = 1\n","\n","# Optimizers\n","sgd_optimizer = torch.optim.SGD(ffnn.parameters(), lr=alpha)\n","adam_optimizer = torch.optim.Adam(ffnn.parameters(), lr=alpha)\n","adamw_optimizer = torch.optim.AdamW(ffnn.parameters(), lr=alpha)\n","rmsprop_optimizer = torch.optim.RMSprop(ffnn.parameters(), lr=alpha)\n","\n","# Loss functions\n","cross_entropy_loss_fn = torch.nn.CrossEntropyLoss()"]},{"cell_type":"code","source":["# FFNN\n","param_grid = {\n","    'hidden_dims': [32, 64, 128, 256, 512],\n","    'activations': [\"relu\", \"tanh\", \"sigmoid\"],\n","    'num_layers': [1, 2, 3, 4, 5],\n","    'include_batch_norm': [True, False],\n","    'initialize_weights': [True, False],\n","    'dropout_rates': [None, 0.1, 0.2, 0.3, 0.4, 0.5],\n","    'batch_sizes': [64, 100, 128, 256, 512],\n","    'grad_clip_max_norms': [None, 1, 2, 3, 4, 5, 6]\n","}\n","\n","grid_search_combinations = list(itertools.product(*param_grid.values()))\n","len(grid_search_combinations)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HEXTvc2OAxvr","executionInfo":{"status":"ok","timestamp":1704028740734,"user_tz":300,"elapsed":165,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"4720aca5-e063-43c3-8476-42bb9df98f1d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["63000"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["# Randomly sample a subset of combinations for random search\n","num_random_samples = 50\n","random_search_combinations = random.sample(grid_search_combinations, num_random_samples)"],"metadata":{"id":"xxPS9ZspBlJK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pfwPFFo-7HG8","executionInfo":{"status":"ok","timestamp":1704029632172,"user_tz":300,"elapsed":335802,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"ecdda92e-2bd8-4492-9e6b-002bb0c1e34d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Training Loss: 0.818, Validation Loss: 0.403, Validation Accuracy: 0.852\n","Epoch 2/10, Training Loss: 0.839, Validation Loss: 1.280, Validation Accuracy: 0.794\n","Epoch 3/10, Training Loss: 1.451, Validation Loss: 1.714, Validation Accuracy: 0.787\n","Epoch 4/10, Training Loss: 1.533, Validation Loss: 1.831, Validation Accuracy: 0.827\n","Epoch 5/10, Training Loss: 1.571, Validation Loss: 1.397, Validation Accuracy: 0.845\n","Epoch 6/10, Training Loss: 1.866, Validation Loss: 2.094, Validation Accuracy: 0.822\n","Epoch 7/10, Training Loss: 1.677, Validation Loss: 1.613, Validation Accuracy: 0.845\n","Epoch 8/10, Training Loss: 1.592, Validation Loss: 2.072, Validation Accuracy: 0.824\n","Epoch 9/10, Training Loss: 2.052, Validation Loss: 3.152, Validation Accuracy: 0.801\n","Epoch 10/10, Training Loss: 2.188, Validation Loss: 3.239, Validation Accuracy: 0.720\n","Minimum Loss: 0.403, Max Accuracy: 0.852\n","Number of iterations: 1\n","Epoch 1/10, Training Loss: 4.634, Validation Loss: 0.357, Validation Accuracy: 0.857\n","Epoch 2/10, Training Loss: 0.314, Validation Loss: 0.281, Validation Accuracy: 0.884\n","Epoch 3/10, Training Loss: 0.267, Validation Loss: 0.263, Validation Accuracy: 0.886\n","Epoch 4/10, Training Loss: 0.250, Validation Loss: 0.276, Validation Accuracy: 0.885\n","Epoch 5/10, Training Loss: 0.248, Validation Loss: 0.262, Validation Accuracy: 0.889\n","Epoch 6/10, Training Loss: 0.241, Validation Loss: 0.273, Validation Accuracy: 0.887\n","Epoch 7/10, Training Loss: 0.240, Validation Loss: 0.268, Validation Accuracy: 0.887\n","Epoch 8/10, Training Loss: 0.246, Validation Loss: 0.267, Validation Accuracy: 0.894\n","Epoch 9/10, Training Loss: 0.239, Validation Loss: 0.293, Validation Accuracy: 0.885\n","Epoch 10/10, Training Loss: 0.249, Validation Loss: 0.301, Validation Accuracy: 0.873\n","Minimum Loss: 0.262, Max Accuracy: 0.894\n","Number of iterations: 2\n","Epoch 1/10, Training Loss: 0.765, Validation Loss: 0.629, Validation Accuracy: 0.853\n","Epoch 2/10, Training Loss: 1.088, Validation Loss: 1.155, Validation Accuracy: 0.846\n","Epoch 3/10, Training Loss: 1.388, Validation Loss: 1.508, Validation Accuracy: 0.790\n","Epoch 4/10, Training Loss: 1.404, Validation Loss: 1.641, Validation Accuracy: 0.828\n","Epoch 5/10, Training Loss: 1.796, Validation Loss: 1.880, Validation Accuracy: 0.861\n","Epoch 6/10, Training Loss: 2.162, Validation Loss: 2.357, Validation Accuracy: 0.799\n","Epoch 7/10, Training Loss: 1.903, Validation Loss: 1.659, Validation Accuracy: 0.851\n","Epoch 8/10, Training Loss: 1.974, Validation Loss: 2.161, Validation Accuracy: 0.837\n","Epoch 9/10, Training Loss: 2.062, Validation Loss: 2.281, Validation Accuracy: 0.830\n","Epoch 10/10, Training Loss: 1.952, Validation Loss: 2.285, Validation Accuracy: 0.794\n","Minimum Loss: 0.629, Max Accuracy: 0.861\n","Number of iterations: 3\n","Epoch 1/10, Training Loss: 1.416, Validation Loss: 0.415, Validation Accuracy: 0.818\n","Epoch 2/10, Training Loss: 0.349, Validation Loss: 0.441, Validation Accuracy: 0.815\n","Epoch 3/10, Training Loss: 0.408, Validation Loss: 0.692, Validation Accuracy: 0.787\n","Epoch 4/10, Training Loss: 0.752, Validation Loss: 1.165, Validation Accuracy: 0.830\n","Epoch 5/10, Training Loss: 1.084, Validation Loss: 1.043, Validation Accuracy: 0.866\n","Epoch 6/10, Training Loss: 1.136, Validation Loss: 1.156, Validation Accuracy: 0.859\n","Epoch 7/10, Training Loss: 1.011, Validation Loss: 1.112, Validation Accuracy: 0.835\n","Epoch 8/10, Training Loss: 1.020, Validation Loss: 1.244, Validation Accuracy: 0.859\n","Epoch 9/10, Training Loss: 1.149, Validation Loss: 1.022, Validation Accuracy: 0.859\n","Epoch 10/10, Training Loss: 1.079, Validation Loss: 0.931, Validation Accuracy: 0.850\n","Minimum Loss: 0.415, Max Accuracy: 0.866\n","Number of iterations: 4\n","Epoch 1/10, Training Loss: 3.036, Validation Loss: 0.302, Validation Accuracy: 0.865\n","Epoch 2/10, Training Loss: 0.282, Validation Loss: 0.274, Validation Accuracy: 0.886\n","Epoch 3/10, Training Loss: 0.260, Validation Loss: 0.269, Validation Accuracy: 0.887\n","Epoch 4/10, Training Loss: 0.251, Validation Loss: 0.260, Validation Accuracy: 0.890\n","Epoch 5/10, Training Loss: 0.251, Validation Loss: 0.288, Validation Accuracy: 0.886\n","Epoch 6/10, Training Loss: 0.250, Validation Loss: 0.274, Validation Accuracy: 0.888\n","Epoch 7/10, Training Loss: 0.240, Validation Loss: 0.282, Validation Accuracy: 0.887\n","Epoch 8/10, Training Loss: 0.239, Validation Loss: 0.260, Validation Accuracy: 0.892\n","Epoch 9/10, Training Loss: 0.245, Validation Loss: 0.309, Validation Accuracy: 0.881\n","Epoch 10/10, Training Loss: 0.246, Validation Loss: 0.275, Validation Accuracy: 0.885\n","Minimum Loss: 0.260, Max Accuracy: 0.892\n","Number of iterations: 5\n","Epoch 1/10, Training Loss: 1.328, Validation Loss: 0.282, Validation Accuracy: 0.878\n","Epoch 2/10, Training Loss: 0.278, Validation Loss: 0.277, Validation Accuracy: 0.883\n","Epoch 3/10, Training Loss: 0.265, Validation Loss: 0.286, Validation Accuracy: 0.882\n","Epoch 4/10, Training Loss: 0.272, Validation Loss: 0.305, Validation Accuracy: 0.879\n","Epoch 5/10, Training Loss: 0.284, Validation Loss: 0.283, Validation Accuracy: 0.880\n","Epoch 6/10, Training Loss: 0.303, Validation Loss: 0.400, Validation Accuracy: 0.858\n","Epoch 7/10, Training Loss: 0.336, Validation Loss: 0.380, Validation Accuracy: 0.853\n","Epoch 8/10, Training Loss: 0.505, Validation Loss: 0.429, Validation Accuracy: 0.857\n","Epoch 9/10, Training Loss: 0.501, Validation Loss: 1.015, Validation Accuracy: 0.742\n","Epoch 10/10, Training Loss: 0.858, Validation Loss: 0.916, Validation Accuracy: 0.858\n","Minimum Loss: 0.277, Max Accuracy: 0.883\n","Number of iterations: 6\n","Epoch 1/10, Training Loss: 0.361, Validation Loss: 0.297, Validation Accuracy: 0.878\n","Epoch 2/10, Training Loss: 0.300, Validation Loss: 0.298, Validation Accuracy: 0.875\n","Epoch 3/10, Training Loss: 0.352, Validation Loss: 0.314, Validation Accuracy: 0.864\n","Epoch 4/10, Training Loss: 0.322, Validation Loss: 0.408, Validation Accuracy: 0.821\n","Epoch 5/10, Training Loss: 0.310, Validation Loss: 0.410, Validation Accuracy: 0.829\n","Epoch 6/10, Training Loss: 0.290, Validation Loss: 0.314, Validation Accuracy: 0.863\n","Epoch 7/10, Training Loss: 0.290, Validation Loss: 0.351, Validation Accuracy: 0.873\n","Epoch 8/10, Training Loss: 0.303, Validation Loss: 0.452, Validation Accuracy: 0.829\n","Epoch 9/10, Training Loss: 0.341, Validation Loss: 0.346, Validation Accuracy: 0.879\n","Epoch 10/10, Training Loss: 0.318, Validation Loss: 0.337, Validation Accuracy: 0.866\n","Minimum Loss: 0.297, Max Accuracy: 0.879\n","Number of iterations: 7\n","Epoch 1/10, Training Loss: 11.139, Validation Loss: 0.492, Validation Accuracy: 0.801\n","Epoch 2/10, Training Loss: 1.569, Validation Loss: 0.408, Validation Accuracy: 0.872\n","Epoch 3/10, Training Loss: 0.408, Validation Loss: 0.322, Validation Accuracy: 0.881\n","Epoch 4/10, Training Loss: 0.311, Validation Loss: 0.296, Validation Accuracy: 0.874\n","Epoch 5/10, Training Loss: 0.281, Validation Loss: 0.313, Validation Accuracy: 0.883\n","Epoch 6/10, Training Loss: 0.310, Validation Loss: 0.326, Validation Accuracy: 0.874\n","Epoch 7/10, Training Loss: 0.820, Validation Loss: 0.690, Validation Accuracy: 0.813\n","Epoch 8/10, Training Loss: 0.563, Validation Loss: 0.429, Validation Accuracy: 0.865\n","Epoch 9/10, Training Loss: 0.691, Validation Loss: 0.874, Validation Accuracy: 0.879\n","Epoch 10/10, Training Loss: 1.153, Validation Loss: 1.156, Validation Accuracy: 0.843\n","Minimum Loss: 0.296, Max Accuracy: 0.883\n","Number of iterations: 8\n","Epoch 1/10, Training Loss: 0.775, Validation Loss: 0.309, Validation Accuracy: 0.871\n","Epoch 2/10, Training Loss: 0.278, Validation Loss: 0.282, Validation Accuracy: 0.884\n","Epoch 3/10, Training Loss: 0.261, Validation Loss: 0.271, Validation Accuracy: 0.886\n","Epoch 4/10, Training Loss: 0.251, Validation Loss: 0.269, Validation Accuracy: 0.887\n","Epoch 5/10, Training Loss: 0.252, Validation Loss: 0.292, Validation Accuracy: 0.873\n","Epoch 6/10, Training Loss: 0.253, Validation Loss: 0.269, Validation Accuracy: 0.895\n","Epoch 7/10, Training Loss: 0.244, Validation Loss: 0.273, Validation Accuracy: 0.889\n","Epoch 8/10, Training Loss: 0.242, Validation Loss: 0.275, Validation Accuracy: 0.885\n","Epoch 9/10, Training Loss: 0.244, Validation Loss: 0.269, Validation Accuracy: 0.882\n","Epoch 10/10, Training Loss: 0.245, Validation Loss: 0.286, Validation Accuracy: 0.885\n","Minimum Loss: 0.269, Max Accuracy: 0.895\n","Number of iterations: 9\n","Epoch 1/10, Training Loss: 1.118, Validation Loss: 0.410, Validation Accuracy: 0.810\n","Epoch 2/10, Training Loss: 0.306, Validation Loss: 0.287, Validation Accuracy: 0.877\n","Epoch 3/10, Training Loss: 0.265, Validation Loss: 0.274, Validation Accuracy: 0.886\n","Epoch 4/10, Training Loss: 0.252, Validation Loss: 0.258, Validation Accuracy: 0.887\n","Epoch 5/10, Training Loss: 0.249, Validation Loss: 0.263, Validation Accuracy: 0.886\n","Epoch 6/10, Training Loss: 0.245, Validation Loss: 0.270, Validation Accuracy: 0.889\n","Epoch 7/10, Training Loss: 0.238, Validation Loss: 0.270, Validation Accuracy: 0.892\n","Epoch 8/10, Training Loss: 0.241, Validation Loss: 0.263, Validation Accuracy: 0.889\n","Epoch 9/10, Training Loss: 0.236, Validation Loss: 0.259, Validation Accuracy: 0.893\n","Epoch 10/10, Training Loss: 0.236, Validation Loss: 0.291, Validation Accuracy: 0.878\n","Minimum Loss: 0.258, Max Accuracy: 0.893\n","Number of iterations: 10\n","Epoch 1/10, Training Loss: 1.031, Validation Loss: 0.471, Validation Accuracy: 0.824\n","Epoch 2/10, Training Loss: 1.088, Validation Loss: 2.531, Validation Accuracy: 0.727\n","Epoch 3/10, Training Loss: 1.513, Validation Loss: 3.348, Validation Accuracy: 0.806\n","Epoch 4/10, Training Loss: 1.712, Validation Loss: 2.020, Validation Accuracy: 0.805\n","Epoch 5/10, Training Loss: 1.608, Validation Loss: 1.593, Validation Accuracy: 0.839\n","Epoch 6/10, Training Loss: 1.789, Validation Loss: 3.526, Validation Accuracy: 0.805\n","Epoch 7/10, Training Loss: 1.790, Validation Loss: 2.288, Validation Accuracy: 0.850\n","Epoch 8/10, Training Loss: 1.808, Validation Loss: 1.893, Validation Accuracy: 0.842\n","Epoch 9/10, Training Loss: 1.890, Validation Loss: 1.725, Validation Accuracy: 0.865\n","Epoch 10/10, Training Loss: 1.809, Validation Loss: 2.448, Validation Accuracy: 0.803\n","Minimum Loss: 0.471, Max Accuracy: 0.865\n","Number of iterations: 11\n","Epoch 1/10, Training Loss: 0.547, Validation Loss: 0.287, Validation Accuracy: 0.880\n","Epoch 2/10, Training Loss: 0.268, Validation Loss: 0.282, Validation Accuracy: 0.880\n","Epoch 3/10, Training Loss: 0.266, Validation Loss: 0.262, Validation Accuracy: 0.888\n","Epoch 4/10, Training Loss: 0.267, Validation Loss: 0.292, Validation Accuracy: 0.874\n","Epoch 5/10, Training Loss: 0.265, Validation Loss: 0.308, Validation Accuracy: 0.881\n","Epoch 6/10, Training Loss: 0.260, Validation Loss: 0.316, Validation Accuracy: 0.878\n","Epoch 7/10, Training Loss: 0.266, Validation Loss: 0.292, Validation Accuracy: 0.879\n","Epoch 8/10, Training Loss: 0.264, Validation Loss: 0.279, Validation Accuracy: 0.880\n","Epoch 9/10, Training Loss: 0.260, Validation Loss: 0.304, Validation Accuracy: 0.871\n","Epoch 10/10, Training Loss: 0.292, Validation Loss: 0.316, Validation Accuracy: 0.865\n","Minimum Loss: 0.262, Max Accuracy: 0.888\n","Number of iterations: 12\n","Epoch 1/10, Training Loss: 1.103, Validation Loss: 0.481, Validation Accuracy: 0.817\n","Epoch 2/10, Training Loss: 0.408, Validation Loss: 0.500, Validation Accuracy: 0.843\n","Epoch 3/10, Training Loss: 0.507, Validation Loss: 0.452, Validation Accuracy: 0.844\n","Epoch 4/10, Training Loss: 0.577, Validation Loss: 1.042, Validation Accuracy: 0.798\n","Epoch 5/10, Training Loss: 0.624, Validation Loss: 0.692, Validation Accuracy: 0.874\n","Epoch 6/10, Training Loss: 0.824, Validation Loss: 0.701, Validation Accuracy: 0.868\n","Epoch 7/10, Training Loss: 0.894, Validation Loss: 1.193, Validation Accuracy: 0.842\n","Epoch 8/10, Training Loss: 0.899, Validation Loss: 1.018, Validation Accuracy: 0.826\n","Epoch 9/10, Training Loss: 1.134, Validation Loss: 1.491, Validation Accuracy: 0.844\n","Epoch 10/10, Training Loss: 0.797, Validation Loss: 1.171, Validation Accuracy: 0.846\n","Minimum Loss: 0.452, Max Accuracy: 0.874\n","Number of iterations: 13\n","Epoch 1/10, Training Loss: 0.428, Validation Loss: 0.286, Validation Accuracy: 0.877\n","Epoch 2/10, Training Loss: 0.275, Validation Loss: 0.280, Validation Accuracy: 0.882\n","Epoch 3/10, Training Loss: 0.277, Validation Loss: 0.317, Validation Accuracy: 0.868\n","Epoch 4/10, Training Loss: 0.302, Validation Loss: 0.387, Validation Accuracy: 0.857\n","Epoch 5/10, Training Loss: 0.408, Validation Loss: 0.358, Validation Accuracy: 0.866\n","Epoch 6/10, Training Loss: 0.345, Validation Loss: 0.323, Validation Accuracy: 0.870\n","Epoch 7/10, Training Loss: 0.313, Validation Loss: 0.315, Validation Accuracy: 0.865\n","Epoch 8/10, Training Loss: 0.318, Validation Loss: 0.332, Validation Accuracy: 0.868\n","Epoch 9/10, Training Loss: 0.378, Validation Loss: 0.319, Validation Accuracy: 0.871\n","Epoch 10/10, Training Loss: 0.373, Validation Loss: 0.396, Validation Accuracy: 0.859\n","Minimum Loss: 0.280, Max Accuracy: 0.882\n","Number of iterations: 14\n","Epoch 1/10, Training Loss: 0.480, Validation Loss: 0.326, Validation Accuracy: 0.873\n","Epoch 2/10, Training Loss: 0.312, Validation Loss: 0.326, Validation Accuracy: 0.858\n","Epoch 3/10, Training Loss: 0.375, Validation Loss: 0.506, Validation Accuracy: 0.871\n","Epoch 4/10, Training Loss: 0.821, Validation Loss: 0.634, Validation Accuracy: 0.835\n","Epoch 5/10, Training Loss: 0.663, Validation Loss: 0.708, Validation Accuracy: 0.800\n","Epoch 6/10, Training Loss: 0.835, Validation Loss: 0.952, Validation Accuracy: 0.860\n","Epoch 7/10, Training Loss: 0.922, Validation Loss: 0.924, Validation Accuracy: 0.857\n","Epoch 8/10, Training Loss: 0.866, Validation Loss: 0.972, Validation Accuracy: 0.855\n","Epoch 9/10, Training Loss: 0.954, Validation Loss: 1.422, Validation Accuracy: 0.865\n","Epoch 10/10, Training Loss: 0.861, Validation Loss: 0.757, Validation Accuracy: 0.843\n","Minimum Loss: 0.326, Max Accuracy: 0.873\n","Number of iterations: 15\n","Epoch 1/10, Training Loss: 0.986, Validation Loss: 0.349, Validation Accuracy: 0.849\n","Epoch 2/10, Training Loss: 0.312, Validation Loss: 0.292, Validation Accuracy: 0.880\n","Epoch 3/10, Training Loss: 0.270, Validation Loss: 0.285, Validation Accuracy: 0.883\n","Epoch 4/10, Training Loss: 0.260, Validation Loss: 0.267, Validation Accuracy: 0.888\n","Epoch 5/10, Training Loss: 0.247, Validation Loss: 0.260, Validation Accuracy: 0.889\n","Epoch 6/10, Training Loss: 0.243, Validation Loss: 0.269, Validation Accuracy: 0.891\n","Epoch 7/10, Training Loss: 0.243, Validation Loss: 0.269, Validation Accuracy: 0.886\n","Epoch 8/10, Training Loss: 0.243, Validation Loss: 0.269, Validation Accuracy: 0.891\n","Epoch 9/10, Training Loss: 0.243, Validation Loss: 0.264, Validation Accuracy: 0.887\n","Epoch 10/10, Training Loss: 0.235, Validation Loss: 0.263, Validation Accuracy: 0.889\n","Minimum Loss: 0.260, Max Accuracy: 0.891\n","Number of iterations: 16\n","Epoch 1/10, Training Loss: 8.162, Validation Loss: 0.347, Validation Accuracy: 0.867\n","Epoch 2/10, Training Loss: 0.555, Validation Loss: 1.380, Validation Accuracy: 0.734\n","Epoch 3/10, Training Loss: 0.811, Validation Loss: 4.232, Validation Accuracy: 0.624\n","Epoch 4/10, Training Loss: 1.358, Validation Loss: 2.408, Validation Accuracy: 0.759\n","Epoch 5/10, Training Loss: 2.240, Validation Loss: 2.245, Validation Accuracy: 0.851\n","Epoch 6/10, Training Loss: 2.593, Validation Loss: 12.187, Validation Accuracy: 0.683\n","Epoch 7/10, Training Loss: 4.334, Validation Loss: 6.486, Validation Accuracy: 0.789\n","Epoch 8/10, Training Loss: 3.828, Validation Loss: 4.828, Validation Accuracy: 0.827\n","Epoch 9/10, Training Loss: 3.533, Validation Loss: 6.760, Validation Accuracy: 0.763\n","Epoch 10/10, Training Loss: 3.816, Validation Loss: 3.133, Validation Accuracy: 0.855\n","Minimum Loss: 0.347, Max Accuracy: 0.867\n","Number of iterations: 17\n","Epoch 1/10, Training Loss: 0.677, Validation Loss: 0.311, Validation Accuracy: 0.886\n","Epoch 2/10, Training Loss: 0.313, Validation Loss: 0.382, Validation Accuracy: 0.876\n","Epoch 3/10, Training Loss: 0.427, Validation Loss: 0.401, Validation Accuracy: 0.865\n","Epoch 4/10, Training Loss: 1.423, Validation Loss: 0.655, Validation Accuracy: 0.839\n","Epoch 5/10, Training Loss: 0.525, Validation Loss: 0.921, Validation Accuracy: 0.843\n","Epoch 6/10, Training Loss: 0.543, Validation Loss: 0.522, Validation Accuracy: 0.869\n","Epoch 7/10, Training Loss: 0.529, Validation Loss: 0.689, Validation Accuracy: 0.823\n","Epoch 8/10, Training Loss: 0.904, Validation Loss: 1.246, Validation Accuracy: 0.858\n","Epoch 9/10, Training Loss: 0.809, Validation Loss: 0.784, Validation Accuracy: 0.862\n","Epoch 10/10, Training Loss: 0.888, Validation Loss: 0.776, Validation Accuracy: 0.851\n","Minimum Loss: 0.311, Max Accuracy: 0.886\n","Number of iterations: 18\n","Epoch 1/10, Training Loss: 0.851, Validation Loss: 0.287, Validation Accuracy: 0.877\n","Epoch 2/10, Training Loss: 0.343, Validation Loss: 0.348, Validation Accuracy: 0.869\n","Epoch 3/10, Training Loss: 0.668, Validation Loss: 0.450, Validation Accuracy: 0.814\n","Epoch 4/10, Training Loss: 0.621, Validation Loss: 0.609, Validation Accuracy: 0.840\n","Epoch 5/10, Training Loss: 0.981, Validation Loss: 1.251, Validation Accuracy: 0.813\n","Epoch 6/10, Training Loss: 1.094, Validation Loss: 0.803, Validation Accuracy: 0.850\n","Epoch 7/10, Training Loss: 0.929, Validation Loss: 1.418, Validation Accuracy: 0.850\n","Epoch 8/10, Training Loss: 0.980, Validation Loss: 0.820, Validation Accuracy: 0.856\n","Epoch 9/10, Training Loss: 0.981, Validation Loss: 0.948, Validation Accuracy: 0.854\n","Epoch 10/10, Training Loss: 1.113, Validation Loss: 1.791, Validation Accuracy: 0.858\n","Minimum Loss: 0.287, Max Accuracy: 0.877\n","Number of iterations: 19\n","Epoch 1/10, Training Loss: 0.496, Validation Loss: 0.295, Validation Accuracy: 0.880\n","Epoch 2/10, Training Loss: 0.269, Validation Loss: 0.273, Validation Accuracy: 0.886\n","Epoch 3/10, Training Loss: 0.265, Validation Loss: 0.282, Validation Accuracy: 0.885\n","Epoch 4/10, Training Loss: 0.277, Validation Loss: 0.338, Validation Accuracy: 0.863\n","Epoch 5/10, Training Loss: 0.284, Validation Loss: 0.286, Validation Accuracy: 0.881\n","Epoch 6/10, Training Loss: 0.271, Validation Loss: 0.297, Validation Accuracy: 0.870\n","Epoch 7/10, Training Loss: 0.287, Validation Loss: 0.283, Validation Accuracy: 0.882\n","Epoch 8/10, Training Loss: 0.268, Validation Loss: 0.284, Validation Accuracy: 0.881\n","Epoch 9/10, Training Loss: 0.258, Validation Loss: 0.295, Validation Accuracy: 0.886\n","Epoch 10/10, Training Loss: 0.260, Validation Loss: 0.283, Validation Accuracy: 0.876\n","Minimum Loss: 0.273, Max Accuracy: 0.886\n","Number of iterations: 20\n","Epoch 1/10, Training Loss: 1.208, Validation Loss: 0.296, Validation Accuracy: 0.872\n","Epoch 2/10, Training Loss: 0.273, Validation Loss: 0.268, Validation Accuracy: 0.890\n","Epoch 3/10, Training Loss: 0.256, Validation Loss: 0.269, Validation Accuracy: 0.886\n","Epoch 4/10, Training Loss: 0.252, Validation Loss: 0.270, Validation Accuracy: 0.889\n","Epoch 5/10, Training Loss: 0.248, Validation Loss: 0.267, Validation Accuracy: 0.889\n","Epoch 6/10, Training Loss: 0.246, Validation Loss: 0.265, Validation Accuracy: 0.892\n","Epoch 7/10, Training Loss: 0.250, Validation Loss: 0.271, Validation Accuracy: 0.885\n","Epoch 8/10, Training Loss: 0.249, Validation Loss: 0.264, Validation Accuracy: 0.891\n","Epoch 9/10, Training Loss: 0.247, Validation Loss: 0.281, Validation Accuracy: 0.881\n","Epoch 10/10, Training Loss: 0.251, Validation Loss: 0.294, Validation Accuracy: 0.879\n","Minimum Loss: 0.264, Max Accuracy: 0.892\n","Number of iterations: 21\n","Epoch 1/10, Training Loss: 10.246, Validation Loss: 1.085, Validation Accuracy: 0.832\n","Epoch 2/10, Training Loss: 0.656, Validation Loss: 0.333, Validation Accuracy: 0.853\n","Epoch 3/10, Training Loss: 0.314, Validation Loss: 0.307, Validation Accuracy: 0.869\n","Epoch 4/10, Training Loss: 0.286, Validation Loss: 0.290, Validation Accuracy: 0.886\n","Epoch 5/10, Training Loss: 0.271, Validation Loss: 0.276, Validation Accuracy: 0.885\n","Epoch 6/10, Training Loss: 0.263, Validation Loss: 0.286, Validation Accuracy: 0.883\n","Epoch 7/10, Training Loss: 0.252, Validation Loss: 0.268, Validation Accuracy: 0.886\n","Epoch 8/10, Training Loss: 0.246, Validation Loss: 0.257, Validation Accuracy: 0.890\n","Epoch 9/10, Training Loss: 0.242, Validation Loss: 0.266, Validation Accuracy: 0.891\n","Epoch 10/10, Training Loss: 0.237, Validation Loss: 0.264, Validation Accuracy: 0.889\n","Minimum Loss: 0.257, Max Accuracy: 0.891\n","Number of iterations: 22\n","Epoch 1/10, Training Loss: 1.863, Validation Loss: 0.310, Validation Accuracy: 0.865\n","Epoch 2/10, Training Loss: 0.275, Validation Loss: 0.268, Validation Accuracy: 0.883\n","Epoch 3/10, Training Loss: 0.262, Validation Loss: 0.298, Validation Accuracy: 0.878\n","Epoch 4/10, Training Loss: 0.255, Validation Loss: 0.265, Validation Accuracy: 0.886\n","Epoch 5/10, Training Loss: 0.249, Validation Loss: 0.262, Validation Accuracy: 0.889\n","Epoch 6/10, Training Loss: 0.247, Validation Loss: 0.269, Validation Accuracy: 0.882\n","Epoch 7/10, Training Loss: 0.257, Validation Loss: 0.283, Validation Accuracy: 0.888\n","Epoch 8/10, Training Loss: 0.249, Validation Loss: 0.270, Validation Accuracy: 0.890\n","Epoch 9/10, Training Loss: 0.244, Validation Loss: 0.284, Validation Accuracy: 0.880\n","Epoch 10/10, Training Loss: 0.244, Validation Loss: 0.270, Validation Accuracy: 0.888\n","Minimum Loss: 0.262, Max Accuracy: 0.890\n","Number of iterations: 23\n","Epoch 1/10, Training Loss: 0.727, Validation Loss: 0.291, Validation Accuracy: 0.877\n","Epoch 2/10, Training Loss: 0.326, Validation Loss: 0.469, Validation Accuracy: 0.827\n","Epoch 3/10, Training Loss: 0.356, Validation Loss: 0.360, Validation Accuracy: 0.877\n","Epoch 4/10, Training Loss: 0.479, Validation Loss: 0.491, Validation Accuracy: 0.821\n","Epoch 5/10, Training Loss: 0.477, Validation Loss: 0.684, Validation Accuracy: 0.819\n","Epoch 6/10, Training Loss: 0.455, Validation Loss: 0.540, Validation Accuracy: 0.847\n","Epoch 7/10, Training Loss: 0.578, Validation Loss: 0.759, Validation Accuracy: 0.817\n","Epoch 8/10, Training Loss: 0.612, Validation Loss: 0.828, Validation Accuracy: 0.835\n","Epoch 9/10, Training Loss: 0.679, Validation Loss: 0.799, Validation Accuracy: 0.838\n","Epoch 10/10, Training Loss: 0.639, Validation Loss: 1.033, Validation Accuracy: 0.877\n","Minimum Loss: 0.291, Max Accuracy: 0.877\n","Number of iterations: 24\n","Epoch 1/10, Training Loss: 0.690, Validation Loss: 0.373, Validation Accuracy: 0.865\n","Epoch 2/10, Training Loss: 0.540, Validation Loss: 0.703, Validation Accuracy: 0.856\n","Epoch 3/10, Training Loss: 0.614, Validation Loss: 0.842, Validation Accuracy: 0.841\n","Epoch 4/10, Training Loss: 0.803, Validation Loss: 0.724, Validation Accuracy: 0.835\n","Epoch 5/10, Training Loss: 0.774, Validation Loss: 0.913, Validation Accuracy: 0.846\n","Epoch 6/10, Training Loss: 0.885, Validation Loss: 0.909, Validation Accuracy: 0.878\n","Epoch 7/10, Training Loss: 0.971, Validation Loss: 0.973, Validation Accuracy: 0.834\n","Epoch 8/10, Training Loss: 1.108, Validation Loss: 1.425, Validation Accuracy: 0.852\n","Epoch 9/10, Training Loss: 0.996, Validation Loss: 1.243, Validation Accuracy: 0.858\n","Epoch 10/10, Training Loss: 1.012, Validation Loss: 0.949, Validation Accuracy: 0.874\n","Minimum Loss: 0.373, Max Accuracy: 0.878\n","Number of iterations: 25\n","Epoch 1/10, Training Loss: 7.270, Validation Loss: 0.683, Validation Accuracy: 0.837\n","Epoch 2/10, Training Loss: 0.507, Validation Loss: 0.355, Validation Accuracy: 0.867\n","Epoch 3/10, Training Loss: 0.290, Validation Loss: 0.297, Validation Accuracy: 0.875\n","Epoch 4/10, Training Loss: 0.259, Validation Loss: 0.315, Validation Accuracy: 0.883\n","Epoch 5/10, Training Loss: 0.254, Validation Loss: 0.271, Validation Accuracy: 0.887\n","Epoch 6/10, Training Loss: 0.246, Validation Loss: 0.292, Validation Accuracy: 0.877\n","Epoch 7/10, Training Loss: 0.248, Validation Loss: 0.274, Validation Accuracy: 0.885\n","Epoch 8/10, Training Loss: 0.251, Validation Loss: 0.292, Validation Accuracy: 0.876\n","Epoch 9/10, Training Loss: 0.247, Validation Loss: 0.275, Validation Accuracy: 0.887\n","Epoch 10/10, Training Loss: 0.247, Validation Loss: 0.285, Validation Accuracy: 0.879\n","Minimum Loss: 0.271, Max Accuracy: 0.887\n","Number of iterations: 26\n","Epoch 1/10, Training Loss: 0.664, Validation Loss: 0.286, Validation Accuracy: 0.881\n","Epoch 2/10, Training Loss: 0.274, Validation Loss: 0.268, Validation Accuracy: 0.885\n","Epoch 3/10, Training Loss: 0.257, Validation Loss: 0.271, Validation Accuracy: 0.885\n","Epoch 4/10, Training Loss: 0.257, Validation Loss: 0.294, Validation Accuracy: 0.878\n","Epoch 5/10, Training Loss: 0.256, Validation Loss: 0.273, Validation Accuracy: 0.885\n","Epoch 6/10, Training Loss: 0.255, Validation Loss: 0.274, Validation Accuracy: 0.891\n","Epoch 7/10, Training Loss: 0.261, Validation Loss: 0.290, Validation Accuracy: 0.889\n","Epoch 8/10, Training Loss: 0.260, Validation Loss: 0.293, Validation Accuracy: 0.878\n","Epoch 9/10, Training Loss: 0.250, Validation Loss: 0.283, Validation Accuracy: 0.884\n","Epoch 10/10, Training Loss: 0.256, Validation Loss: 0.306, Validation Accuracy: 0.882\n","Minimum Loss: 0.268, Max Accuracy: 0.891\n","Number of iterations: 27\n","Epoch 1/10, Training Loss: 0.631, Validation Loss: 0.279, Validation Accuracy: 0.881\n","Epoch 2/10, Training Loss: 0.262, Validation Loss: 0.266, Validation Accuracy: 0.889\n","Epoch 3/10, Training Loss: 0.254, Validation Loss: 0.266, Validation Accuracy: 0.888\n","Epoch 4/10, Training Loss: 0.253, Validation Loss: 0.283, Validation Accuracy: 0.889\n","Epoch 5/10, Training Loss: 0.269, Validation Loss: 0.268, Validation Accuracy: 0.890\n","Epoch 6/10, Training Loss: 0.259, Validation Loss: 0.298, Validation Accuracy: 0.885\n","Epoch 7/10, Training Loss: 0.252, Validation Loss: 0.338, Validation Accuracy: 0.876\n","Epoch 8/10, Training Loss: 0.267, Validation Loss: 0.301, Validation Accuracy: 0.886\n","Epoch 9/10, Training Loss: 0.263, Validation Loss: 0.332, Validation Accuracy: 0.884\n","Epoch 10/10, Training Loss: 0.266, Validation Loss: 0.322, Validation Accuracy: 0.858\n","Minimum Loss: 0.266, Max Accuracy: 0.890\n","Number of iterations: 28\n","Epoch 1/10, Training Loss: 0.789, Validation Loss: 0.287, Validation Accuracy: 0.888\n","Epoch 2/10, Training Loss: 0.313, Validation Loss: 0.316, Validation Accuracy: 0.873\n","Epoch 3/10, Training Loss: 0.371, Validation Loss: 0.861, Validation Accuracy: 0.840\n","Epoch 4/10, Training Loss: 0.647, Validation Loss: 1.114, Validation Accuracy: 0.805\n","Epoch 5/10, Training Loss: 1.199, Validation Loss: 1.460, Validation Accuracy: 0.827\n","Epoch 6/10, Training Loss: 1.094, Validation Loss: 1.344, Validation Accuracy: 0.843\n","Epoch 7/10, Training Loss: 1.054, Validation Loss: 1.024, Validation Accuracy: 0.874\n","Epoch 8/10, Training Loss: 0.990, Validation Loss: 0.921, Validation Accuracy: 0.861\n","Epoch 9/10, Training Loss: 1.001, Validation Loss: 1.672, Validation Accuracy: 0.791\n","Epoch 10/10, Training Loss: 1.122, Validation Loss: 1.254, Validation Accuracy: 0.850\n","Minimum Loss: 0.287, Max Accuracy: 0.888\n","Number of iterations: 29\n","Epoch 1/10, Training Loss: 5.573, Validation Loss: 0.708, Validation Accuracy: 0.697\n","Epoch 2/10, Training Loss: 0.428, Validation Loss: 0.324, Validation Accuracy: 0.861\n","Epoch 3/10, Training Loss: 0.284, Validation Loss: 0.277, Validation Accuracy: 0.877\n","Epoch 4/10, Training Loss: 0.264, Validation Loss: 0.266, Validation Accuracy: 0.886\n","Epoch 5/10, Training Loss: 0.250, Validation Loss: 0.265, Validation Accuracy: 0.888\n","Epoch 6/10, Training Loss: 0.246, Validation Loss: 0.274, Validation Accuracy: 0.887\n","Epoch 7/10, Training Loss: 0.245, Validation Loss: 0.265, Validation Accuracy: 0.889\n","Epoch 8/10, Training Loss: 0.240, Validation Loss: 0.262, Validation Accuracy: 0.887\n","Epoch 9/10, Training Loss: 0.238, Validation Loss: 0.261, Validation Accuracy: 0.893\n","Epoch 10/10, Training Loss: 0.239, Validation Loss: 0.261, Validation Accuracy: 0.891\n","Minimum Loss: 0.261, Max Accuracy: 0.893\n","Number of iterations: 30\n","Epoch 1/10, Training Loss: 0.516, Validation Loss: 0.357, Validation Accuracy: 0.881\n","Epoch 2/10, Training Loss: 0.356, Validation Loss: 0.418, Validation Accuracy: 0.825\n","Epoch 3/10, Training Loss: 0.777, Validation Loss: 0.707, Validation Accuracy: 0.791\n","Epoch 4/10, Training Loss: 0.697, Validation Loss: 0.630, Validation Accuracy: 0.803\n","Epoch 5/10, Training Loss: 0.744, Validation Loss: 0.670, Validation Accuracy: 0.861\n","Epoch 6/10, Training Loss: 0.678, Validation Loss: 0.838, Validation Accuracy: 0.855\n","Epoch 7/10, Training Loss: 0.803, Validation Loss: 0.855, Validation Accuracy: 0.864\n","Epoch 8/10, Training Loss: 0.805, Validation Loss: 1.070, Validation Accuracy: 0.864\n","Epoch 9/10, Training Loss: 0.900, Validation Loss: 0.916, Validation Accuracy: 0.877\n","Epoch 10/10, Training Loss: 0.982, Validation Loss: 1.408, Validation Accuracy: 0.831\n","Minimum Loss: 0.357, Max Accuracy: 0.881\n","Number of iterations: 31\n","Epoch 1/10, Training Loss: 0.766, Validation Loss: 0.281, Validation Accuracy: 0.882\n","Epoch 2/10, Training Loss: 0.271, Validation Loss: 0.271, Validation Accuracy: 0.890\n","Epoch 3/10, Training Loss: 0.266, Validation Loss: 0.319, Validation Accuracy: 0.873\n","Epoch 4/10, Training Loss: 0.276, Validation Loss: 0.280, Validation Accuracy: 0.880\n","Epoch 5/10, Training Loss: 0.282, Validation Loss: 0.373, Validation Accuracy: 0.846\n","Epoch 6/10, Training Loss: 0.311, Validation Loss: 0.398, Validation Accuracy: 0.874\n","Epoch 7/10, Training Loss: 0.321, Validation Loss: 0.387, Validation Accuracy: 0.855\n","Epoch 8/10, Training Loss: 0.353, Validation Loss: 0.387, Validation Accuracy: 0.865\n","Epoch 9/10, Training Loss: 0.435, Validation Loss: 0.593, Validation Accuracy: 0.835\n","Epoch 10/10, Training Loss: 0.397, Validation Loss: 0.450, Validation Accuracy: 0.847\n","Minimum Loss: 0.271, Max Accuracy: 0.890\n","Number of iterations: 32\n","Epoch 1/10, Training Loss: 0.433, Validation Loss: 0.284, Validation Accuracy: 0.886\n","Epoch 2/10, Training Loss: 0.278, Validation Loss: 0.336, Validation Accuracy: 0.874\n","Epoch 3/10, Training Loss: 0.272, Validation Loss: 0.311, Validation Accuracy: 0.873\n","Epoch 4/10, Training Loss: 0.285, Validation Loss: 0.308, Validation Accuracy: 0.875\n","Epoch 5/10, Training Loss: 0.310, Validation Loss: 0.363, Validation Accuracy: 0.885\n","Epoch 6/10, Training Loss: 0.281, Validation Loss: 0.348, Validation Accuracy: 0.858\n","Epoch 7/10, Training Loss: 0.311, Validation Loss: 0.344, Validation Accuracy: 0.878\n","Epoch 8/10, Training Loss: 0.299, Validation Loss: 0.324, Validation Accuracy: 0.873\n","Epoch 9/10, Training Loss: 0.336, Validation Loss: 0.448, Validation Accuracy: 0.846\n","Epoch 10/10, Training Loss: 0.376, Validation Loss: 0.339, Validation Accuracy: 0.858\n","Minimum Loss: 0.284, Max Accuracy: 0.886\n","Number of iterations: 33\n","Epoch 1/10, Training Loss: 2.526, Validation Loss: 1.600, Validation Accuracy: 0.825\n","Epoch 2/10, Training Loss: 3.200, Validation Loss: 12.304, Validation Accuracy: 0.742\n","Epoch 3/10, Training Loss: 6.672, Validation Loss: 7.270, Validation Accuracy: 0.861\n","Epoch 4/10, Training Loss: 6.483, Validation Loss: 5.635, Validation Accuracy: 0.835\n","Epoch 5/10, Training Loss: 6.730, Validation Loss: 6.659, Validation Accuracy: 0.836\n","Epoch 6/10, Training Loss: 7.551, Validation Loss: 6.735, Validation Accuracy: 0.857\n","Epoch 7/10, Training Loss: 7.882, Validation Loss: 13.746, Validation Accuracy: 0.815\n","Epoch 8/10, Training Loss: 7.946, Validation Loss: 7.167, Validation Accuracy: 0.859\n","Epoch 9/10, Training Loss: 7.733, Validation Loss: 7.459, Validation Accuracy: 0.811\n","Epoch 10/10, Training Loss: 8.167, Validation Loss: 10.852, Validation Accuracy: 0.788\n","Minimum Loss: 1.600, Max Accuracy: 0.861\n","Number of iterations: 34\n","Epoch 1/10, Training Loss: 0.454, Validation Loss: 0.278, Validation Accuracy: 0.884\n","Epoch 2/10, Training Loss: 0.277, Validation Loss: 0.289, Validation Accuracy: 0.880\n","Epoch 3/10, Training Loss: 0.274, Validation Loss: 0.284, Validation Accuracy: 0.888\n","Epoch 4/10, Training Loss: 0.275, Validation Loss: 0.313, Validation Accuracy: 0.881\n","Epoch 5/10, Training Loss: 0.291, Validation Loss: 0.308, Validation Accuracy: 0.871\n","Epoch 6/10, Training Loss: 0.329, Validation Loss: 0.343, Validation Accuracy: 0.872\n","Epoch 7/10, Training Loss: 0.307, Validation Loss: 0.318, Validation Accuracy: 0.868\n","Epoch 8/10, Training Loss: 0.328, Validation Loss: 0.330, Validation Accuracy: 0.880\n","Epoch 9/10, Training Loss: 0.336, Validation Loss: 0.429, Validation Accuracy: 0.865\n","Epoch 10/10, Training Loss: 0.337, Validation Loss: 0.403, Validation Accuracy: 0.864\n","Minimum Loss: 0.278, Max Accuracy: 0.888\n","Number of iterations: 35\n","Epoch 1/10, Training Loss: 1.014, Validation Loss: 0.367, Validation Accuracy: 0.854\n","Epoch 2/10, Training Loss: 0.680, Validation Loss: 2.877, Validation Accuracy: 0.640\n","Epoch 3/10, Training Loss: 3.142, Validation Loss: 2.584, Validation Accuracy: 0.862\n","Epoch 4/10, Training Loss: 3.657, Validation Loss: 3.087, Validation Accuracy: 0.805\n","Epoch 5/10, Training Loss: 2.587, Validation Loss: 7.229, Validation Accuracy: 0.708\n","Epoch 6/10, Training Loss: 3.495, Validation Loss: 3.788, Validation Accuracy: 0.839\n","Epoch 7/10, Training Loss: 3.298, Validation Loss: 3.007, Validation Accuracy: 0.876\n","Epoch 8/10, Training Loss: 3.500, Validation Loss: 3.784, Validation Accuracy: 0.845\n","Epoch 9/10, Training Loss: 3.966, Validation Loss: 4.215, Validation Accuracy: 0.851\n","Epoch 10/10, Training Loss: 3.944, Validation Loss: 3.532, Validation Accuracy: 0.866\n","Minimum Loss: 0.367, Max Accuracy: 0.876\n","Number of iterations: 36\n","Epoch 1/10, Training Loss: 1.150, Validation Loss: 0.295, Validation Accuracy: 0.874\n","Epoch 2/10, Training Loss: 0.268, Validation Loss: 0.277, Validation Accuracy: 0.887\n","Epoch 3/10, Training Loss: 0.258, Validation Loss: 0.283, Validation Accuracy: 0.880\n","Epoch 4/10, Training Loss: 0.251, Validation Loss: 0.268, Validation Accuracy: 0.889\n","Epoch 5/10, Training Loss: 0.250, Validation Loss: 0.277, Validation Accuracy: 0.882\n","Epoch 6/10, Training Loss: 0.245, Validation Loss: 0.270, Validation Accuracy: 0.884\n","Epoch 7/10, Training Loss: 0.247, Validation Loss: 0.302, Validation Accuracy: 0.874\n","Epoch 8/10, Training Loss: 0.248, Validation Loss: 0.277, Validation Accuracy: 0.887\n","Epoch 9/10, Training Loss: 0.244, Validation Loss: 0.277, Validation Accuracy: 0.885\n","Epoch 10/10, Training Loss: 0.242, Validation Loss: 0.274, Validation Accuracy: 0.891\n","Minimum Loss: 0.268, Max Accuracy: 0.891\n","Number of iterations: 37\n","Epoch 1/10, Training Loss: 0.915, Validation Loss: 0.288, Validation Accuracy: 0.879\n","Epoch 2/10, Training Loss: 0.281, Validation Loss: 0.326, Validation Accuracy: 0.864\n","Epoch 3/10, Training Loss: 0.286, Validation Loss: 0.283, Validation Accuracy: 0.883\n","Epoch 4/10, Training Loss: 0.326, Validation Loss: 0.411, Validation Accuracy: 0.825\n","Epoch 5/10, Training Loss: 0.355, Validation Loss: 0.433, Validation Accuracy: 0.877\n","Epoch 6/10, Training Loss: 0.387, Validation Loss: 0.324, Validation Accuracy: 0.877\n","Epoch 7/10, Training Loss: 0.518, Validation Loss: 0.516, Validation Accuracy: 0.846\n","Epoch 8/10, Training Loss: 0.466, Validation Loss: 0.515, Validation Accuracy: 0.865\n","Epoch 9/10, Training Loss: 0.519, Validation Loss: 0.772, Validation Accuracy: 0.783\n","Epoch 10/10, Training Loss: 0.572, Validation Loss: 0.632, Validation Accuracy: 0.863\n","Minimum Loss: 0.283, Max Accuracy: 0.883\n","Number of iterations: 38\n","Epoch 1/10, Training Loss: 0.493, Validation Loss: 0.354, Validation Accuracy: 0.872\n","Epoch 2/10, Training Loss: 0.366, Validation Loss: 0.439, Validation Accuracy: 0.861\n","Epoch 3/10, Training Loss: 0.499, Validation Loss: 1.674, Validation Accuracy: 0.795\n","Epoch 4/10, Training Loss: 0.883, Validation Loss: 1.151, Validation Accuracy: 0.696\n","Epoch 5/10, Training Loss: 0.958, Validation Loss: 1.225, Validation Accuracy: 0.867\n","Epoch 6/10, Training Loss: 0.974, Validation Loss: 0.968, Validation Accuracy: 0.872\n","Epoch 7/10, Training Loss: 0.839, Validation Loss: 1.720, Validation Accuracy: 0.781\n","Epoch 8/10, Training Loss: 0.844, Validation Loss: 0.876, Validation Accuracy: 0.859\n","Epoch 9/10, Training Loss: 0.780, Validation Loss: 0.874, Validation Accuracy: 0.834\n","Epoch 10/10, Training Loss: 0.827, Validation Loss: 1.235, Validation Accuracy: 0.867\n","Minimum Loss: 0.354, Max Accuracy: 0.872\n","Number of iterations: 39\n","Epoch 1/10, Training Loss: 5.537, Validation Loss: 0.795, Validation Accuracy: 0.741\n","Epoch 2/10, Training Loss: 0.370, Validation Loss: 0.316, Validation Accuracy: 0.862\n","Epoch 3/10, Training Loss: 0.283, Validation Loss: 0.272, Validation Accuracy: 0.889\n","Epoch 4/10, Training Loss: 0.253, Validation Loss: 0.310, Validation Accuracy: 0.866\n","Epoch 5/10, Training Loss: 0.250, Validation Loss: 0.287, Validation Accuracy: 0.876\n","Epoch 6/10, Training Loss: 0.253, Validation Loss: 0.267, Validation Accuracy: 0.887\n","Epoch 7/10, Training Loss: 0.240, Validation Loss: 0.276, Validation Accuracy: 0.886\n","Epoch 8/10, Training Loss: 0.246, Validation Loss: 0.269, Validation Accuracy: 0.883\n","Epoch 9/10, Training Loss: 0.237, Validation Loss: 0.284, Validation Accuracy: 0.884\n","Epoch 10/10, Training Loss: 0.247, Validation Loss: 0.334, Validation Accuracy: 0.876\n","Minimum Loss: 0.267, Max Accuracy: 0.889\n","Number of iterations: 40\n","Epoch 1/10, Training Loss: 0.374, Validation Loss: 0.282, Validation Accuracy: 0.878\n","Epoch 2/10, Training Loss: 0.291, Validation Loss: 0.290, Validation Accuracy: 0.879\n","Epoch 3/10, Training Loss: 0.378, Validation Loss: 0.369, Validation Accuracy: 0.867\n","Epoch 4/10, Training Loss: 0.339, Validation Loss: 0.301, Validation Accuracy: 0.876\n","Epoch 5/10, Training Loss: 0.300, Validation Loss: 0.361, Validation Accuracy: 0.876\n","Epoch 6/10, Training Loss: 0.331, Validation Loss: 0.420, Validation Accuracy: 0.827\n","Epoch 7/10, Training Loss: 0.343, Validation Loss: 0.411, Validation Accuracy: 0.879\n","Epoch 8/10, Training Loss: 0.370, Validation Loss: 0.478, Validation Accuracy: 0.877\n","Epoch 9/10, Training Loss: 0.368, Validation Loss: 0.439, Validation Accuracy: 0.874\n","Epoch 10/10, Training Loss: 0.359, Validation Loss: 0.333, Validation Accuracy: 0.878\n","Minimum Loss: 0.282, Max Accuracy: 0.879\n","Number of iterations: 41\n","Epoch 1/10, Training Loss: 2.169, Validation Loss: 0.417, Validation Accuracy: 0.805\n","Epoch 2/10, Training Loss: 0.329, Validation Loss: 0.339, Validation Accuracy: 0.878\n","Epoch 3/10, Training Loss: 0.352, Validation Loss: 0.349, Validation Accuracy: 0.870\n","Epoch 4/10, Training Loss: 1.180, Validation Loss: 1.077, Validation Accuracy: 0.864\n","Epoch 5/10, Training Loss: 1.303, Validation Loss: 1.342, Validation Accuracy: 0.861\n","Epoch 6/10, Training Loss: 1.188, Validation Loss: 1.288, Validation Accuracy: 0.848\n","Epoch 7/10, Training Loss: 1.620, Validation Loss: 1.222, Validation Accuracy: 0.858\n","Epoch 8/10, Training Loss: 2.020, Validation Loss: 2.344, Validation Accuracy: 0.824\n","Epoch 9/10, Training Loss: 1.912, Validation Loss: 1.847, Validation Accuracy: 0.855\n","Epoch 10/10, Training Loss: 2.058, Validation Loss: 2.564, Validation Accuracy: 0.857\n","Minimum Loss: 0.339, Max Accuracy: 0.878\n","Number of iterations: 42\n","Epoch 1/10, Training Loss: 0.912, Validation Loss: 0.344, Validation Accuracy: 0.863\n","Epoch 2/10, Training Loss: 0.574, Validation Loss: 0.751, Validation Accuracy: 0.873\n","Epoch 3/10, Training Loss: 0.585, Validation Loss: 0.714, Validation Accuracy: 0.822\n","Epoch 4/10, Training Loss: 0.868, Validation Loss: 0.995, Validation Accuracy: 0.829\n","Epoch 5/10, Training Loss: 0.906, Validation Loss: 0.801, Validation Accuracy: 0.844\n","Epoch 6/10, Training Loss: 1.018, Validation Loss: 0.715, Validation Accuracy: 0.840\n","Epoch 7/10, Training Loss: 1.150, Validation Loss: 1.486, Validation Accuracy: 0.835\n","Epoch 8/10, Training Loss: 1.169, Validation Loss: 2.051, Validation Accuracy: 0.811\n","Epoch 9/10, Training Loss: 1.320, Validation Loss: 1.581, Validation Accuracy: 0.860\n","Epoch 10/10, Training Loss: 1.296, Validation Loss: 2.171, Validation Accuracy: 0.754\n","Minimum Loss: 0.344, Max Accuracy: 0.873\n","Number of iterations: 43\n","Epoch 1/10, Training Loss: 9.935, Validation Loss: 1.302, Validation Accuracy: 0.852\n","Epoch 2/10, Training Loss: 1.907, Validation Loss: 1.907, Validation Accuracy: 0.846\n","Epoch 3/10, Training Loss: 1.911, Validation Loss: 3.501, Validation Accuracy: 0.762\n","Epoch 4/10, Training Loss: 2.709, Validation Loss: 1.662, Validation Accuracy: 0.842\n","Epoch 5/10, Training Loss: 2.390, Validation Loss: 3.029, Validation Accuracy: 0.835\n","Epoch 6/10, Training Loss: 3.353, Validation Loss: 4.450, Validation Accuracy: 0.833\n","Epoch 7/10, Training Loss: 2.952, Validation Loss: 3.549, Validation Accuracy: 0.817\n","Epoch 8/10, Training Loss: 3.216, Validation Loss: 4.006, Validation Accuracy: 0.825\n","Epoch 9/10, Training Loss: 3.427, Validation Loss: 5.235, Validation Accuracy: 0.792\n","Epoch 10/10, Training Loss: 3.636, Validation Loss: 5.326, Validation Accuracy: 0.817\n","Minimum Loss: 1.302, Max Accuracy: 0.852\n","Number of iterations: 44\n","Epoch 1/10, Training Loss: 2.250, Validation Loss: 0.677, Validation Accuracy: 0.771\n","Epoch 2/10, Training Loss: 0.373, Validation Loss: 0.282, Validation Accuracy: 0.882\n","Epoch 3/10, Training Loss: 0.262, Validation Loss: 0.265, Validation Accuracy: 0.887\n","Epoch 4/10, Training Loss: 0.251, Validation Loss: 0.275, Validation Accuracy: 0.886\n","Epoch 5/10, Training Loss: 0.246, Validation Loss: 0.290, Validation Accuracy: 0.881\n","Epoch 6/10, Training Loss: 0.249, Validation Loss: 0.265, Validation Accuracy: 0.886\n","Epoch 7/10, Training Loss: 0.244, Validation Loss: 0.308, Validation Accuracy: 0.879\n","Epoch 8/10, Training Loss: 0.248, Validation Loss: 0.263, Validation Accuracy: 0.891\n","Epoch 9/10, Training Loss: 0.243, Validation Loss: 0.262, Validation Accuracy: 0.890\n","Epoch 10/10, Training Loss: 0.237, Validation Loss: 0.315, Validation Accuracy: 0.870\n","Minimum Loss: 0.262, Max Accuracy: 0.891\n","Number of iterations: 45\n","Epoch 1/10, Training Loss: 0.581, Validation Loss: 0.380, Validation Accuracy: 0.861\n","Epoch 2/10, Training Loss: 1.160, Validation Loss: 0.658, Validation Accuracy: 0.852\n","Epoch 3/10, Training Loss: 1.224, Validation Loss: 0.937, Validation Accuracy: 0.870\n","Epoch 4/10, Training Loss: 1.410, Validation Loss: 1.833, Validation Accuracy: 0.835\n","Epoch 5/10, Training Loss: 1.767, Validation Loss: 2.573, Validation Accuracy: 0.849\n","Epoch 6/10, Training Loss: 1.823, Validation Loss: 2.145, Validation Accuracy: 0.824\n","Epoch 7/10, Training Loss: 2.104, Validation Loss: 2.499, Validation Accuracy: 0.853\n","Epoch 8/10, Training Loss: 1.932, Validation Loss: 1.895, Validation Accuracy: 0.845\n","Epoch 9/10, Training Loss: 1.847, Validation Loss: 1.807, Validation Accuracy: 0.854\n","Epoch 10/10, Training Loss: 2.208, Validation Loss: 2.484, Validation Accuracy: 0.830\n","Minimum Loss: 0.380, Max Accuracy: 0.870\n","Number of iterations: 46\n","Epoch 1/10, Training Loss: 0.629, Validation Loss: 0.285, Validation Accuracy: 0.879\n","Epoch 2/10, Training Loss: 0.275, Validation Loss: 0.308, Validation Accuracy: 0.883\n","Epoch 3/10, Training Loss: 0.278, Validation Loss: 0.353, Validation Accuracy: 0.864\n","Epoch 4/10, Training Loss: 0.294, Validation Loss: 0.370, Validation Accuracy: 0.879\n","Epoch 5/10, Training Loss: 0.306, Validation Loss: 0.355, Validation Accuracy: 0.863\n","Epoch 6/10, Training Loss: 0.364, Validation Loss: 0.575, Validation Accuracy: 0.834\n","Epoch 7/10, Training Loss: 0.310, Validation Loss: 0.353, Validation Accuracy: 0.876\n","Epoch 8/10, Training Loss: 0.295, Validation Loss: 0.342, Validation Accuracy: 0.873\n","Epoch 9/10, Training Loss: 0.335, Validation Loss: 0.382, Validation Accuracy: 0.852\n","Epoch 10/10, Training Loss: 0.333, Validation Loss: 0.376, Validation Accuracy: 0.875\n","Minimum Loss: 0.285, Max Accuracy: 0.883\n","Number of iterations: 47\n","Epoch 1/10, Training Loss: 3.040, Validation Loss: 1.704, Validation Accuracy: 0.493\n","Epoch 2/10, Training Loss: 0.687, Validation Loss: 0.283, Validation Accuracy: 0.879\n","Epoch 3/10, Training Loss: 0.281, Validation Loss: 0.295, Validation Accuracy: 0.878\n","Epoch 4/10, Training Loss: 0.253, Validation Loss: 0.272, Validation Accuracy: 0.888\n","Epoch 5/10, Training Loss: 0.260, Validation Loss: 0.272, Validation Accuracy: 0.886\n","Epoch 6/10, Training Loss: 0.271, Validation Loss: 0.274, Validation Accuracy: 0.879\n","Epoch 7/10, Training Loss: 0.271, Validation Loss: 0.312, Validation Accuracy: 0.867\n","Epoch 8/10, Training Loss: 0.272, Validation Loss: 0.373, Validation Accuracy: 0.862\n","Epoch 9/10, Training Loss: 0.251, Validation Loss: 0.293, Validation Accuracy: 0.880\n","Epoch 10/10, Training Loss: 0.260, Validation Loss: 0.310, Validation Accuracy: 0.880\n","Minimum Loss: 0.272, Max Accuracy: 0.888\n","Number of iterations: 48\n","Epoch 1/10, Training Loss: 0.949, Validation Loss: 0.383, Validation Accuracy: 0.819\n","Epoch 2/10, Training Loss: 0.305, Validation Loss: 0.277, Validation Accuracy: 0.880\n","Epoch 3/10, Training Loss: 0.263, Validation Loss: 0.273, Validation Accuracy: 0.882\n","Epoch 4/10, Training Loss: 0.252, Validation Loss: 0.269, Validation Accuracy: 0.888\n","Epoch 5/10, Training Loss: 0.246, Validation Loss: 0.271, Validation Accuracy: 0.882\n","Epoch 6/10, Training Loss: 0.243, Validation Loss: 0.270, Validation Accuracy: 0.888\n","Epoch 7/10, Training Loss: 0.240, Validation Loss: 0.265, Validation Accuracy: 0.889\n","Epoch 8/10, Training Loss: 0.240, Validation Loss: 0.262, Validation Accuracy: 0.893\n","Epoch 9/10, Training Loss: 0.235, Validation Loss: 0.263, Validation Accuracy: 0.892\n","Epoch 10/10, Training Loss: 0.233, Validation Loss: 0.256, Validation Accuracy: 0.891\n","Minimum Loss: 0.256, Max Accuracy: 0.893\n","Number of iterations: 49\n","Epoch 1/10, Training Loss: 7.836, Validation Loss: 0.405, Validation Accuracy: 0.818\n","Epoch 2/10, Training Loss: 0.424, Validation Loss: 0.293, Validation Accuracy: 0.879\n","Epoch 3/10, Training Loss: 0.276, Validation Loss: 0.266, Validation Accuracy: 0.886\n","Epoch 4/10, Training Loss: 0.266, Validation Loss: 0.272, Validation Accuracy: 0.885\n","Epoch 5/10, Training Loss: 0.253, Validation Loss: 0.290, Validation Accuracy: 0.887\n","Epoch 6/10, Training Loss: 0.250, Validation Loss: 0.299, Validation Accuracy: 0.881\n","Epoch 7/10, Training Loss: 0.264, Validation Loss: 0.330, Validation Accuracy: 0.868\n","Epoch 8/10, Training Loss: 0.263, Validation Loss: 0.289, Validation Accuracy: 0.878\n","Epoch 9/10, Training Loss: 0.245, Validation Loss: 0.266, Validation Accuracy: 0.888\n","Epoch 10/10, Training Loss: 0.244, Validation Loss: 0.267, Validation Accuracy: 0.884\n","Minimum Loss: 0.266, Max Accuracy: 0.888\n","Number of iterations: 50\n"]}],"source":["iteration_count = 0  # Initialize the counter\n","\n","results = []\n","for (\n","    hidden_dim,\n","    activation,\n","    num_layer,\n","    include_batch_norm,\n","    initialize_weights,\n","    dropout_rate,\n","    batch_size,\n","    grad_clip_max_norm\n","    ) in random_search_combinations:\n","\n","    iteration_count += 1  # Increment the counter for each iteration\n","\n","    # FFNN Architecture\n","    ffnn = FFNN(\n","        embedding_dim=embedding_dim,\n","        hidden_dim=hidden_dim,\n","        output_dim=output_dim,\n","        num_layers=num_layers,\n","        include_batch_norm=include_batch_norm,\n","        initialize_weights=initialize_weights,\n","        dropout_rate=dropout_rate\n","    )\n","\n","    # Optimizer\n","    adam_optimizer = torch.optim.Adam(ffnn.parameters(), lr=alpha)\n","\n","    # Training\n","    best_validation_loss, best_validation_accuracy = train(\n","        Xs_tr,\n","        Ys_tr,\n","        Xs_va,\n","        Ys_va,\n","        ffnn,\n","        cross_entropy_loss_fn,\n","        adam_optimizer,\n","        epochs,\n","        batch_size,\n","        grad_clip_max_norm\n","    )\n","\n","    # Result\n","    result = dict(\n","        zip(\n","            param_grid.keys(),\n","            (hidden_dim, activation, num_layer, include_batch_norm, initialize_weights, dropout_rate)\n","        )\n","    )\n","    result[\"best_validation_loss\"] = best_validation_loss\n","    result[\"best_validation_accuracy\"] = best_validation_accuracy\n","    result[\"iteration\"] = iteration_count  # Add the iteration count to the result\n","    results.append(result)\n","\n","    print(\"Number of iterations:\", iteration_count)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Nu208sec7HG8","executionInfo":{"status":"ok","timestamp":1704029636165,"user_tz":300,"elapsed":144,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"d2ac3565-bc34-425f-92fa-5680b3fec0f9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    hidden_dims activations  num_layers  include_batch_norm  \\\n","0           128     sigmoid           3                True   \n","1           128        tanh           5               False   \n","2           128     sigmoid           4               False   \n","3           128        relu           3               False   \n","4           128        relu           1               False   \n","5           128        relu           3                True   \n","6            32        tanh           2                True   \n","7           512        tanh           4               False   \n","8            64        tanh           1               False   \n","9            64        tanh           1                True   \n","10          128        relu           1                True   \n","11           32        relu           2                True   \n","12          128        relu           1               False   \n","13           32        relu           4                True   \n","14           64     sigmoid           1                True   \n","15           32     sigmoid           4                True   \n","16          512        tanh           2                True   \n","17          128        tanh           5                True   \n","18          128        tanh           1                True   \n","19           32        relu           4                True   \n","20           64        tanh           2                True   \n","21          256     sigmoid           3                True   \n","22          128        tanh           1               False   \n","23           64     sigmoid           2                True   \n","24           64        tanh           4                True   \n","25          128        relu           4                True   \n","26           64     sigmoid           3                True   \n","27           32        tanh           2               False   \n","28          128        tanh           2               False   \n","29          128        relu           2                True   \n","30           64        tanh           4                True   \n","31           64        tanh           3                True   \n","32           32        tanh           1               False   \n","33          512     sigmoid           5               False   \n","34           32     sigmoid           4                True   \n","35          256     sigmoid           5               False   \n","36           64        tanh           4               False   \n","37           64        tanh           5                True   \n","38           64        relu           3                True   \n","39           64        tanh           1               False   \n","40           32        relu           1               False   \n","41          256        relu           4                True   \n","42          128     sigmoid           3               False   \n","43          512        relu           4               False   \n","44           64        tanh           4                True   \n","45          128     sigmoid           1               False   \n","46           32        relu           5                True   \n","47          128        relu           1               False   \n","48           32        relu           5                True   \n","49          256        tanh           1               False   \n","\n","    initialize_weights  dropout_rates  best_validation_loss  \\\n","0                 True            0.4              0.403304   \n","1                False            0.1              0.262024   \n","2                 True            0.2              0.629443   \n","3                False            0.4              0.415441   \n","4                False            0.1              0.259905   \n","5                False            NaN              0.276657   \n","6                False            0.2              0.296509   \n","7                False            NaN              0.296433   \n","8                False            0.3              0.268754   \n","9                 True            0.2              0.257817   \n","10                True            0.2              0.471089   \n","11               False            0.5              0.261569   \n","12               False            0.5              0.451644   \n","13               False            0.1              0.280306   \n","14               False            0.2              0.325970   \n","15               False            0.4              0.260192   \n","16               False            NaN              0.347037   \n","17                True            0.4              0.310517   \n","18                True            NaN              0.287033   \n","19               False            0.1              0.273469   \n","20                True            0.1              0.263972   \n","21               False            0.1              0.256612   \n","22               False            0.3              0.262421   \n","23                True            0.4              0.290747   \n","24               False            NaN              0.372705   \n","25                True            0.2              0.271107   \n","26                True            0.4              0.268245   \n","27               False            NaN              0.265645   \n","28                True            0.1              0.286921   \n","29               False            0.5              0.260520   \n","30               False            0.5              0.357129   \n","31               False            0.2              0.270625   \n","32                True            0.5              0.283955   \n","33               False            0.4              1.600405   \n","34                True            0.3              0.277838   \n","35                True            0.1              0.367457   \n","36               False            0.3              0.268051   \n","37               False            0.1              0.283396   \n","38               False            0.2              0.353545   \n","39                True            0.5              0.266532   \n","40                True            0.1              0.282430   \n","41                True            0.2              0.339422   \n","42                True            0.1              0.344361   \n","43                True            NaN              1.302105   \n","44                True            0.2              0.262005   \n","45                True            NaN              0.379568   \n","46               False            0.4              0.284547   \n","47                True            0.2              0.271548   \n","48               False            0.2              0.255995   \n","49                True            0.5              0.265649   \n","\n","    best_validation_accuracy  iteration  \n","0                   0.852000          1  \n","1                   0.894133          2  \n","2                   0.861067          3  \n","3                   0.866133          4  \n","4                   0.892000          5  \n","5                   0.883200          6  \n","6                   0.879200          7  \n","7                   0.882933          8  \n","8                   0.894667          9  \n","9                   0.892800         10  \n","10                  0.865067         11  \n","11                  0.888267         12  \n","12                  0.874133         13  \n","13                  0.881600         14  \n","14                  0.872800         15  \n","15                  0.891200         16  \n","16                  0.867200         17  \n","17                  0.886133         18  \n","18                  0.876800         19  \n","19                  0.886133         20  \n","20                  0.892000         21  \n","21                  0.891200         22  \n","22                  0.889867         23  \n","23                  0.877067         24  \n","24                  0.877600         25  \n","25                  0.886933         26  \n","26                  0.890933         27  \n","27                  0.889600         28  \n","28                  0.888000         29  \n","29                  0.892533         30  \n","30                  0.880800         31  \n","31                  0.889600         32  \n","32                  0.885867         33  \n","33                  0.861067         34  \n","34                  0.887733         35  \n","35                  0.876267         36  \n","36                  0.890933         37  \n","37                  0.882667         38  \n","38                  0.872267         39  \n","39                  0.889067         40  \n","40                  0.879200         41  \n","41                  0.878133         42  \n","42                  0.872800         43  \n","43                  0.851733         44  \n","44                  0.891200         45  \n","45                  0.870400         46  \n","46                  0.883467         47  \n","47                  0.887733         48  \n","48                  0.892533         49  \n","49                  0.888267         50  "],"text/html":["\n","  <div id=\"df-1dd1479b-1ad9-4eb4-be8d-1d14233e7495\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>hidden_dims</th>\n","      <th>activations</th>\n","      <th>num_layers</th>\n","      <th>include_batch_norm</th>\n","      <th>initialize_weights</th>\n","      <th>dropout_rates</th>\n","      <th>best_validation_loss</th>\n","      <th>best_validation_accuracy</th>\n","      <th>iteration</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>128</td>\n","      <td>sigmoid</td>\n","      <td>3</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>0.4</td>\n","      <td>0.403304</td>\n","      <td>0.852000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>128</td>\n","      <td>tanh</td>\n","      <td>5</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>0.1</td>\n","      <td>0.262024</td>\n","      <td>0.894133</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>128</td>\n","      <td>sigmoid</td>\n","      <td>4</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>0.2</td>\n","      <td>0.629443</td>\n","      <td>0.861067</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>128</td>\n","      <td>relu</td>\n","      <td>3</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>0.4</td>\n","      <td>0.415441</td>\n","      <td>0.866133</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>128</td>\n","      <td>relu</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>0.1</td>\n","      <td>0.259905</td>\n","      <td>0.892000</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>128</td>\n","      <td>relu</td>\n","      <td>3</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>NaN</td>\n","      <td>0.276657</td>\n","      <td>0.883200</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>32</td>\n","      <td>tanh</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>0.2</td>\n","      <td>0.296509</td>\n","      <td>0.879200</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>512</td>\n","      <td>tanh</td>\n","      <td>4</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>NaN</td>\n","      <td>0.296433</td>\n","      <td>0.882933</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>64</td>\n","      <td>tanh</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>0.3</td>\n","      <td>0.268754</td>\n","      <td>0.894667</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>64</td>\n","      <td>tanh</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>0.2</td>\n","      <td>0.257817</td>\n","      <td>0.892800</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>128</td>\n","      <td>relu</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>0.2</td>\n","      <td>0.471089</td>\n","      <td>0.865067</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>32</td>\n","      <td>relu</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>0.5</td>\n","      <td>0.261569</td>\n","      <td>0.888267</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>128</td>\n","      <td>relu</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>0.5</td>\n","      <td>0.451644</td>\n","      <td>0.874133</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>32</td>\n","      <td>relu</td>\n","      <td>4</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>0.1</td>\n","      <td>0.280306</td>\n","      <td>0.881600</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>64</td>\n","      <td>sigmoid</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>0.2</td>\n","      <td>0.325970</td>\n","      <td>0.872800</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>32</td>\n","      <td>sigmoid</td>\n","      <td>4</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>0.4</td>\n","      <td>0.260192</td>\n","      <td>0.891200</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>512</td>\n","      <td>tanh</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>NaN</td>\n","      <td>0.347037</td>\n","      <td>0.867200</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>128</td>\n","      <td>tanh</td>\n","      <td>5</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>0.4</td>\n","      <td>0.310517</td>\n","      <td>0.886133</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>128</td>\n","      <td>tanh</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>NaN</td>\n","      <td>0.287033</td>\n","      <td>0.876800</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>32</td>\n","      <td>relu</td>\n","      <td>4</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>0.1</td>\n","      <td>0.273469</td>\n","      <td>0.886133</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>64</td>\n","      <td>tanh</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>0.1</td>\n","      <td>0.263972</td>\n","      <td>0.892000</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>256</td>\n","      <td>sigmoid</td>\n","      <td>3</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>0.1</td>\n","      <td>0.256612</td>\n","      <td>0.891200</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>128</td>\n","      <td>tanh</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>0.3</td>\n","      <td>0.262421</td>\n","      <td>0.889867</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>64</td>\n","      <td>sigmoid</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>0.4</td>\n","      <td>0.290747</td>\n","      <td>0.877067</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>64</td>\n","      <td>tanh</td>\n","      <td>4</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>NaN</td>\n","      <td>0.372705</td>\n","      <td>0.877600</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>128</td>\n","      <td>relu</td>\n","      <td>4</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>0.2</td>\n","      <td>0.271107</td>\n","      <td>0.886933</td>\n","      <td>26</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>64</td>\n","      <td>sigmoid</td>\n","      <td>3</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>0.4</td>\n","      <td>0.268245</td>\n","      <td>0.890933</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>32</td>\n","      <td>tanh</td>\n","      <td>2</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>NaN</td>\n","      <td>0.265645</td>\n","      <td>0.889600</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>128</td>\n","      <td>tanh</td>\n","      <td>2</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>0.1</td>\n","      <td>0.286921</td>\n","      <td>0.888000</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>128</td>\n","      <td>relu</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>0.5</td>\n","      <td>0.260520</td>\n","      <td>0.892533</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>64</td>\n","      <td>tanh</td>\n","      <td>4</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>0.5</td>\n","      <td>0.357129</td>\n","      <td>0.880800</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>64</td>\n","      <td>tanh</td>\n","      <td>3</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>0.2</td>\n","      <td>0.270625</td>\n","      <td>0.889600</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>32</td>\n","      <td>tanh</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>0.5</td>\n","      <td>0.283955</td>\n","      <td>0.885867</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>512</td>\n","      <td>sigmoid</td>\n","      <td>5</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>0.4</td>\n","      <td>1.600405</td>\n","      <td>0.861067</td>\n","      <td>34</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>32</td>\n","      <td>sigmoid</td>\n","      <td>4</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>0.3</td>\n","      <td>0.277838</td>\n","      <td>0.887733</td>\n","      <td>35</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>256</td>\n","      <td>sigmoid</td>\n","      <td>5</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>0.1</td>\n","      <td>0.367457</td>\n","      <td>0.876267</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>64</td>\n","      <td>tanh</td>\n","      <td>4</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>0.3</td>\n","      <td>0.268051</td>\n","      <td>0.890933</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>64</td>\n","      <td>tanh</td>\n","      <td>5</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>0.1</td>\n","      <td>0.283396</td>\n","      <td>0.882667</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>64</td>\n","      <td>relu</td>\n","      <td>3</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>0.2</td>\n","      <td>0.353545</td>\n","      <td>0.872267</td>\n","      <td>39</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>64</td>\n","      <td>tanh</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>0.5</td>\n","      <td>0.266532</td>\n","      <td>0.889067</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>32</td>\n","      <td>relu</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>0.1</td>\n","      <td>0.282430</td>\n","      <td>0.879200</td>\n","      <td>41</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>256</td>\n","      <td>relu</td>\n","      <td>4</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>0.2</td>\n","      <td>0.339422</td>\n","      <td>0.878133</td>\n","      <td>42</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>128</td>\n","      <td>sigmoid</td>\n","      <td>3</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>0.1</td>\n","      <td>0.344361</td>\n","      <td>0.872800</td>\n","      <td>43</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>512</td>\n","      <td>relu</td>\n","      <td>4</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>NaN</td>\n","      <td>1.302105</td>\n","      <td>0.851733</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>64</td>\n","      <td>tanh</td>\n","      <td>4</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>0.2</td>\n","      <td>0.262005</td>\n","      <td>0.891200</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>128</td>\n","      <td>sigmoid</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>NaN</td>\n","      <td>0.379568</td>\n","      <td>0.870400</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>32</td>\n","      <td>relu</td>\n","      <td>5</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>0.4</td>\n","      <td>0.284547</td>\n","      <td>0.883467</td>\n","      <td>47</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>128</td>\n","      <td>relu</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>0.2</td>\n","      <td>0.271548</td>\n","      <td>0.887733</td>\n","      <td>48</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>32</td>\n","      <td>relu</td>\n","      <td>5</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>0.2</td>\n","      <td>0.255995</td>\n","      <td>0.892533</td>\n","      <td>49</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>256</td>\n","      <td>tanh</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>0.5</td>\n","      <td>0.265649</td>\n","      <td>0.888267</td>\n","      <td>50</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1dd1479b-1ad9-4eb4-be8d-1d14233e7495')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1dd1479b-1ad9-4eb4-be8d-1d14233e7495 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1dd1479b-1ad9-4eb4-be8d-1d14233e7495');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d7d6e277-caf2-49c0-a908-f8be01dd2fa1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7d6e277-caf2-49c0-a908-f8be01dd2fa1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d7d6e277-caf2-49c0-a908-f8be01dd2fa1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_f2f38cfd-abb8-4585-b204-aeda3d7151a4\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_f2f38cfd-abb8-4585-b204-aeda3d7151a4 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('result_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":59}],"source":["result_df = pd.DataFrame(results)\n","result_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"gJPFtirM7HG8","executionInfo":{"status":"ok","timestamp":1704029645856,"user_tz":300,"elapsed":171,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"ec657d1e-60f7-4a7c-cf5e-05af73e664cb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   hidden_dims activations  num_layers  include_batch_norm  \\\n","8           64        tanh           1               False   \n","\n","   initialize_weights  dropout_rates  best_validation_loss  \\\n","8               False            0.3              0.268754   \n","\n","   best_validation_accuracy  iteration  \n","8                  0.894667          9  "],"text/html":["\n","  <div id=\"df-bb6437e9-c0bd-47dc-b02c-dea075871b73\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>hidden_dims</th>\n","      <th>activations</th>\n","      <th>num_layers</th>\n","      <th>include_batch_norm</th>\n","      <th>initialize_weights</th>\n","      <th>dropout_rates</th>\n","      <th>best_validation_loss</th>\n","      <th>best_validation_accuracy</th>\n","      <th>iteration</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>8</th>\n","      <td>64</td>\n","      <td>tanh</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>0.3</td>\n","      <td>0.268754</td>\n","      <td>0.894667</td>\n","      <td>9</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb6437e9-c0bd-47dc-b02c-dea075871b73')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bb6437e9-c0bd-47dc-b02c-dea075871b73 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bb6437e9-c0bd-47dc-b02c-dea075871b73');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":60}],"source":["result_df.loc[result_df.best_validation_accuracy == result_df.best_validation_accuracy.max(), :]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2kZhaN_Y7HG9","executionInfo":{"status":"ok","timestamp":1704029659010,"user_tz":300,"elapsed":149,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"2f55f9e2-7b38-48b3-b110-0236d6f877b9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8946666666666667"]},"metadata":{},"execution_count":61}],"source":["result_df.best_validation_accuracy.max()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"liA5Pqo87HG9"},"outputs":[],"source":["result_df.to_csv(\"architecture_result.csv\")"]},{"cell_type":"markdown","metadata":{"id":"Y_3f9th77HG9"},"source":["# 8. Submission"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"Was0zJe87HG9","executionInfo":{"status":"ok","timestamp":1704119119382,"user_tz":300,"elapsed":5,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}}},"outputs":[],"source":["def make_prediction(Xs_te, model):\n","    Y_preds_prob = model(Xs_te)\n","    Y_preds = torch.argmax(Y_preds_prob, axis = 1)\n","    return Y_preds"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"qGLp9b237HG9","executionInfo":{"status":"ok","timestamp":1704119119382,"user_tz":300,"elapsed":3,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}}},"outputs":[],"source":["def make_submission(uid, Y_preds):\n","    df = pd.DataFrame({'uid': uid, 'preference': Y_preds})\n","    df.to_csv('submission.csv', index = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PizrB4Sf7HG9"},"outputs":[],"source":["Xs_te = np.concatenate((test_data['emb1'], test_data['emb2']), axis=1)\n","Xs_te = torch.Tensor(Xs_te)\n","Y_preds = make_prediction(Xs_te, ffnn)\n","make_submission(test_data['uid'], np.array(Y_preds))"]},{"cell_type":"markdown","metadata":{"id":"u0UFwcnH7HG9"},"source":["# 9. Appendix"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-uRs4TGk7HG9","executionInfo":{"status":"ok","timestamp":1704029668770,"user_tz":300,"elapsed":128,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"33c5328f-dcfe-4e45-abb6-87cb2032de6f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["RNN(\n","  (hidden_layers): RNN(768, 256, batch_first=True)\n","  (output_layer): Linear(in_features=256, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":66}],"source":["class RNN(nn.Module):\n","    def __init__(self, embedding_dim, hidden_dim, output_dim, num_layers):\n","        super().__init__()\n","        self.hidden_layers = nn.RNN(embedding_dim, hidden_dim, num_layers, batch_first=True)\n","        self.output_layer = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        # Forward pass through the RNN layer\n","        out, _ = self.hidden_layers(x)\n","\n","        # Take the output from the last time step and pass it through the fully connected layer\n","        out = self.output_layer(out)\n","        return out\n","\n","rnn = RNN(embedding_dim, hidden_dim, output_dim, num_layers)\n","rnn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xh508Sfd7HG-","executionInfo":{"status":"ok","timestamp":1704031124219,"user_tz":300,"elapsed":57480,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"db20ef3d-ab6c-450a-9181-9b03b25b30f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Training Loss: 0.6622525453567505, Validation Loss: 0.694, Validation Accuracy: 0.500\n","Epoch 2/10, Training Loss: 0.7058525681495667, Validation Loss: 0.694, Validation Accuracy: 0.499\n","Epoch 3/10, Training Loss: 0.7326067686080933, Validation Loss: 0.694, Validation Accuracy: 0.499\n","Epoch 4/10, Training Loss: 0.7132993936538696, Validation Loss: 0.694, Validation Accuracy: 0.499\n","Epoch 5/10, Training Loss: 0.6166714429855347, Validation Loss: 0.694, Validation Accuracy: 0.500\n","Epoch 6/10, Training Loss: 0.6832106709480286, Validation Loss: 0.692, Validation Accuracy: 0.499\n","Epoch 7/10, Training Loss: 0.69664067029953, Validation Loss: 0.694, Validation Accuracy: 0.500\n","Epoch 8/10, Training Loss: 0.6812561750411987, Validation Loss: 0.694, Validation Accuracy: 0.499\n","Epoch 9/10, Training Loss: 0.6765474677085876, Validation Loss: 0.694, Validation Accuracy: 0.500\n","Epoch 10/10, Training Loss: 0.6975078582763672, Validation Loss: 0.693, Validation Accuracy: 0.499\n","Minimum Loss: 0.692, Max Accuracy: 0.500\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.6921877190470695, 0.5)"]},"metadata":{},"execution_count":79}],"source":["# RNN\n","train(Xs_tr, Ys_tr, Xs_va, Ys_va, rnn, cross_entropy_loss_fn, adam_optimizer, epochs, grad_clip_max_norm)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rmu5pl0j7HG-","executionInfo":{"status":"ok","timestamp":1704031124220,"user_tz":300,"elapsed":6,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"e3e88ac4-6bc7-422f-deed-3dd5a6ac606a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["LSTM(\n","  (hidden_layers): LSTM(768, 256, batch_first=True)\n","  (output_layer): Linear(in_features=256, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":80}],"source":["class LSTM(nn.Module):\n","    def __init__(self, embedding_dim, hidden_dim, output_dim, num_layers):\n","        super().__init__()\n","        self.hidden_layers = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n","        self.output_layer = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        # Forward pass through the RNN layer\n","        out, _ = self.hidden_layers(x)\n","\n","        # Take the output from the last time step and pass it through the fully connected layer\n","        out = self.output_layer(out)\n","        return out\n","\n","lstm = LSTM(embedding_dim, hidden_dim, output_dim, num_layers)\n","lstm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q1iEnffO7HG-","executionInfo":{"status":"ok","timestamp":1704031293276,"user_tz":300,"elapsed":169059,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"dc4d6840-b510-43e2-c709-71786785fa2a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Training Loss: 0.6907047033309937, Validation Loss: 0.693, Validation Accuracy: 0.500\n","Epoch 2/10, Training Loss: 0.6963127851486206, Validation Loss: 0.693, Validation Accuracy: 0.500\n","Epoch 3/10, Training Loss: 0.6875535249710083, Validation Loss: 0.693, Validation Accuracy: 0.499\n","Epoch 4/10, Training Loss: 0.6954268217086792, Validation Loss: 0.693, Validation Accuracy: 0.500\n","Epoch 5/10, Training Loss: 0.7069279551506042, Validation Loss: 0.693, Validation Accuracy: 0.499\n","Epoch 6/10, Training Loss: 0.6905986070632935, Validation Loss: 0.693, Validation Accuracy: 0.500\n","Epoch 7/10, Training Loss: 0.6969180703163147, Validation Loss: 0.693, Validation Accuracy: 0.499\n","Epoch 8/10, Training Loss: 0.706170916557312, Validation Loss: 0.693, Validation Accuracy: 0.500\n","Epoch 9/10, Training Loss: 0.6837252378463745, Validation Loss: 0.694, Validation Accuracy: 0.499\n","Epoch 10/10, Training Loss: 0.6918861269950867, Validation Loss: 0.694, Validation Accuracy: 0.500\n","Minimum Loss: 0.693, Max Accuracy: 0.500\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.6931802779436111, 0.5002666666666666)"]},"metadata":{},"execution_count":81}],"source":["# LSTM\n","train(Xs_tr, Ys_tr, Xs_va, Ys_va, lstm, cross_entropy_loss_fn, adam_optimizer, epochs, grad_clip_max_norm)"]},{"cell_type":"code","source":["class Perceptron(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(Perceptron, self).__init__()\n","        self.linear = nn.Linear(input_dim, output_dim)\n","\n","    def forward(self, x):\n","        return self.linear(x)\n","\n","input_dim = Xs_tr.shape[1]\n","output_dim = 2\n","\n","perceptron = Perceptron(input_dim, output_dim)\n","perceptron"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"khAVsdvAGvkZ","executionInfo":{"status":"ok","timestamp":1704118859146,"user_tz":300,"elapsed":171,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"b4c7f7fd-89d9-4dbc-89a9-e13afc9c9feb"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Perceptron(\n","  (linear): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# Perceptron\n","train(Xs_tr, Ys_tr, Xs_va, Ys_va, perceptron, cross_entropy_loss_fn, adam_optimizer, epochs, grad_clip_max_norm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tj-QKCC1GvH2","executionInfo":{"status":"ok","timestamp":1704031311125,"user_tz":300,"elapsed":17854,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"30d56b93-0479-433e-a806-0ad7fd068400"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Training Loss: 0.6937889456748962, Validation Loss: 0.694, Validation Accuracy: 0.500\n","Epoch 2/10, Training Loss: 0.7078548669815063, Validation Loss: 0.694, Validation Accuracy: 0.500\n","Epoch 3/10, Training Loss: 0.6957200765609741, Validation Loss: 0.694, Validation Accuracy: 0.500\n","Epoch 4/10, Training Loss: 0.6686443090438843, Validation Loss: 0.694, Validation Accuracy: 0.500\n","Epoch 5/10, Training Loss: 0.6857262849807739, Validation Loss: 0.694, Validation Accuracy: 0.500\n","Epoch 6/10, Training Loss: 0.6737910509109497, Validation Loss: 0.693, Validation Accuracy: 0.500\n","Epoch 7/10, Training Loss: 0.7012429237365723, Validation Loss: 0.693, Validation Accuracy: 0.500\n","Epoch 8/10, Training Loss: 0.6913532614707947, Validation Loss: 0.694, Validation Accuracy: 0.500\n","Epoch 9/10, Training Loss: 0.6994125843048096, Validation Loss: 0.693, Validation Accuracy: 0.500\n","Epoch 10/10, Training Loss: 0.6675577163696289, Validation Loss: 0.694, Validation Accuracy: 0.500\n","Minimum Loss: 0.693, Max Accuracy: 0.500\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.6930814981460571, 0.5002666666666666)"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","\n","class SVM:\n","    def __init__(self, kernel='linear', C=1.0):\n","        self.model = SVC(kernel=kernel, C=C)\n","\n","    def fit(self, X, Y):\n","        self.model.fit(X, Y)\n","\n","    def predict(self, X):\n","        return self.model.predict(X)\n","\n","def train_svm(Xs_tr, Ys_tr, Xs_va, Ys_va, svm):\n","    # Train the SVM model\n","    svm.fit(Xs_tr, Ys_tr)\n","\n","    # Predict on the validation set\n","    predictions = svm.predict(Xs_va)\n","\n","    # Evaluate accuracy\n","    accuracy = accuracy_score(Ys_va, predictions)\n","    print(f\"Validation Accuracy: {accuracy:.3f}\")\n","\n","    return accuracy\n","\n","# Example usage\n","svm = SVM(kernel='linear', C=1.0)\n","accuracy = train_svm(Xs_tr, Ys_tr, Xs_va, Ys_va, svm)\n","print(f\"Final Validation Accuracy: {accuracy:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4lKx_V691IrF","executionInfo":{"status":"ok","timestamp":1704119833942,"user_tz":300,"elapsed":47597,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}},"outputId":"ced1d956-6b66-492f-bc85-504eac406e72"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.894\n","Final Validation Accuracy: 0.894\n"]}]},{"cell_type":"code","source":["Xs_te = np.concatenate((test_data['emb1'], test_data['emb2']), axis=1)\n","Xs_te = torch.Tensor(Xs_te)\n","Y_preds = svm.predict(Xs_te)\n","make_submission(test_data['uid'], np.array(Y_preds))"],"metadata":{"id":"BkwR-eo4cKqV","executionInfo":{"status":"ok","timestamp":1704119843046,"user_tz":300,"elapsed":9106,"user":{"displayName":"Steven Wang","userId":"08142172156487005980"}}},"execution_count":31,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}